{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b12b90b4",
   "metadata": {},
   "source": [
    "# Обучение CNN модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc67dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aec16f8",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05636a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"images/train\"\n",
    "test_data_path = \"images/test\"\n",
    "\n",
    "train_df = pd.read_csv(\"Train.csv\")\n",
    "test_df = pd.read_csv(\"Test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a91bc65",
   "metadata": {},
   "source": [
    "### Извлечение сегментов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed50c9b0",
   "metadata": {},
   "source": [
    "Теперь нужно подготовить датасет для обучения модели-регрессора. Сперва извлечём сегменты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a62bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"early\" : YOLO(\"seg_models/best_early.pt\"),\n",
    "          \"late\" : YOLO(\"seg_models/best_late.pt\"),\n",
    "          \"full\" : YOLO(\"seg_models/best_full.pt\"),\n",
    "          \"best\" : YOLO(\"seg_models/best.pt\")}\n",
    "\n",
    "def get_segmented_images(models, image_paths, display_image=False, do_segment = True):\n",
    "    \"\"\"Извлечение детектированных сегментов\"\"\"\n",
    "    best_res = None\n",
    "    for model in models.keys():\n",
    "        model = models[model]\n",
    "        results = model(image_paths, verbose=False)\n",
    "        if best_res is None or len(results[0].boxes.xyxy) >= len(best_res[0].boxes.xyxy):\n",
    "            best_res = results\n",
    "        # if len(results[0].boxes.xyxy) != 0:\n",
    "        #     break\n",
    "\n",
    "    results = best_res\n",
    "\n",
    "    was_segmented = len(results[0].boxes) > 3\n",
    "\n",
    "    if len(results[0].boxes.xyxy) == 0 or not do_segment:\n",
    "        # в случае отсутствия детекций\n",
    "        return [Image.open(img) for img in image_paths], was_segmented\n",
    "        \n",
    "    segmented_images = []\n",
    "    \n",
    "    for img_path, result in zip(image_paths, results):\n",
    "        original_image = Image.open(img_path)\n",
    "        \n",
    "        # Пропускаем изображения без детекций\n",
    "        if len(result.boxes.xyxy) == 0:\n",
    "            continue \n",
    "            \n",
    "        # Оставляем сегменты\n",
    "        for box in result.boxes.xyxy:\n",
    "            x1, y1, x2, y2 = map(int, box.tolist())\n",
    "            segment = original_image.crop((x1, y1, x2, y2))\n",
    "            segmented_images.append(segment)\n",
    "            \n",
    "\n",
    "    # Отрисовка для демонстрации\n",
    "    if display_image and segmented_images:\n",
    "        fig, axes = plt.subplots(1, len(segmented_images), figsize=(15, 10))\n",
    "        if len(segmented_images) == 1:\n",
    "            axes = [axes]\n",
    "        for ax, img in zip(axes, segmented_images):\n",
    "            ax.imshow(img)\n",
    "            ax.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    return segmented_images, was_segmented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17566c77",
   "metadata": {},
   "source": [
    "### Загрузка серии срезов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef79746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(img_root : str, folder : str, side : str, start : int, end : int) -> list[str]:\n",
    "    \"\"\"Получение списка последовательности изображений\n",
    "\n",
    "    Args:\n",
    "        img_root (str): корневая папка с изображениями\n",
    "        folder (str): папка корня\n",
    "        side (str): (L|R) сторона\n",
    "        start (int): начальный срез\n",
    "        end (int): конечный срез\n",
    "\n",
    "    Returns:\n",
    "        list[str]: список путей до изображений\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for i in range(start, end + 1):\n",
    "        path = os.path.join(\n",
    "            img_root,\n",
    "            folder,\n",
    "            f\"{folder}_{side}_{i:03d}.png\"\n",
    "        )\n",
    "        if os.path.exists(path):\n",
    "            images.append(path)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8915c7",
   "metadata": {},
   "source": [
    "### Компоновка сегментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_segmented_images(root: str, folder: str, side: str, start: int, end: int, do_segment = True) -> Image:\n",
    "    \"\"\"Компоновка сегментов по серии срезов\n",
    "\n",
    "    Args:\n",
    "        root (str): корневой путь\n",
    "        folder (str): папка корня\n",
    "        side (str): (L|R) сторона\n",
    "        start (int): начальный срез\n",
    "        end (int): конечный срез\n",
    "\n",
    "    Returns:\n",
    "        Image: Итоговое изображение PIL.Image\n",
    "    \"\"\"\n",
    "    images_in_range = get_images(root, folder, side, start, end)\n",
    "    segmented_images, was_segmented = get_segmented_images(models, images_in_range, do_segment=do_segment)\n",
    "\n",
    "    total_width = sum(img.width for img in segmented_images)\n",
    "    max_height = max(img.height for img in segmented_images)\n",
    "    res = Image.new(\"RGBA\", (total_width, max_height * len(segmented_images)), (0, 0, 0, 0))\n",
    "    sqr_width = int(np.ceil(np.sqrt(total_width * max_height)))\n",
    "    x_offset = 0\n",
    "    y_offset = 0\n",
    "    actual_width = 0\n",
    "    for segment in segmented_images:\n",
    "        if x_offset + segment.width > sqr_width:\n",
    "            actual_width = max(actual_width, x_offset)\n",
    "            x_offset = 0\n",
    "            y_offset += max_height\n",
    "        res.paste(segment, (x_offset, y_offset))\n",
    "        x_offset += segment.width\n",
    "    actual_width = max(actual_width, x_offset)\n",
    "    actual_height = y_offset + max_height\n",
    "    res = res.crop((0, 0, actual_width, actual_height))\n",
    "\n",
    "    return res, was_segmented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5f2fa9",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92003edf",
   "metadata": {},
   "source": [
    "Предварительно будем трансформировать данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f472071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad626c8",
   "metadata": {},
   "source": [
    "### Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c438be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RootVolumeDataset(Dataset):\n",
    "    def __init__(self, df : pd.DataFrame, transform = None, is_train = True):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.df['ImageSegments'].iloc[index]).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.is_train:\n",
    "            label = self.df['RootVolume'].iloc[index]\n",
    "\n",
    "            return image, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb32f5c",
   "metadata": {},
   "source": [
    "Воспроизводимость результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211131e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed) \n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    L.pytorch.seed_everything(seed, workers=True)\n",
    "    \n",
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd82610",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = v2.Compose([\n",
    "    v2.Resize(size=(128, 128), antialias=True),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),  \n",
    "    v2.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "test_transform = v2.Compose([\n",
    "    v2.Resize(size=(128, 128), antialias=True),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),  \n",
    "    v2.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33fdf3f",
   "metadata": {},
   "source": [
    "### Регрессор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43a6ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RootVolumeRegressor(L.LightningModule):\n",
    "    def __init__(self, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "\n",
    "        # Fully Connected Regression Head\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)  # Regression output\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        preds = self(images).squeeze()\n",
    "        loss = self.criterion(preds, targets)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        preds = self(images).squeeze()\n",
    "        loss = self.criterion(preds, targets)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc6de7b",
   "metadata": {},
   "source": [
    "### Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcf3c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_preds(model, dataloader, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    preds, targets = [], []\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images, labels = batch\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)  # Predict\n",
    "\n",
    "            preds.extend(outputs.cpu().numpy().flatten())\n",
    "            targets.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "    return np.array(preds), np.array(targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f986081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(preds, targets):\n",
    "    \"\"\"\n",
    "    Compute Root Mean Squared Error (RMSE) between predictions and ground truth targets.\n",
    "    \"\"\"\n",
    "    preds = np.array(preds) if not isinstance(preds, np.ndarray) else preds\n",
    "    targets = np.array(targets) if not isinstance(targets, np.ndarray) else targets\n",
    "    \n",
    "    return np.sqrt(np.mean((preds - targets) ** 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b6cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MAPE(preds, targets):\n",
    "    preds = np.array(preds) if not isinstance(preds, np.ndarray) else preds\n",
    "    targets = np.array(targets) if not isinstance(targets, np.ndarray) else targets\n",
    "    res = []\n",
    "    for i in range(len(targets)):\n",
    "        target = targets[i]\n",
    "        pred = preds[i]\n",
    "        if abs(target) < 1e-3:\n",
    "            continue\n",
    "        res.append((np.abs(pred - target) / target) * 100)\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bdc90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_preds(model, dataloader, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    preds = []\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images = batch if isinstance(batch, torch.Tensor) else batch[0]\n",
    "            images = images.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            preds.extend(outputs.cpu().numpy().flatten()) \n",
    "\n",
    "    return np.array(preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d705dac0",
   "metadata": {},
   "source": [
    "### Без сегментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d724bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regression_dataset(df : pd.DataFrame, output : str, src : str, type : str, do_segment : bool = False):\n",
    "    paths = []\n",
    "    was_segmented = []\n",
    "    widths = []\n",
    "    for _, row in tqdm(df.iterrows(), total = len(df), desc=\"Генерация датасета\"):\n",
    "        img, segm = merge_segmented_images(\n",
    "            root=src,\n",
    "            folder=row[\"FolderName\"],\n",
    "            side=row[\"Side\"],\n",
    "            start=row[\"Start\"],\n",
    "            end=row[\"End\"],\n",
    "            do_segment=do_segment\n",
    "        )\n",
    "        img_path = os.path.join(output, f'{row[\"ID\"]}.png')\n",
    "        img.save(img_path)\n",
    "        paths.append(img_path)\n",
    "        was_segmented.append(segm)\n",
    "        widths.append(img.width)\n",
    "    df[\"WasSegmented\"] = was_segmented\n",
    "    df[\"ImageSegments\"] = paths\n",
    "    df[\"Width\"] = widths\n",
    "    df.to_csv(f\"{type}CNN.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_root = \"merged_images\"\n",
    "\n",
    "output_train = os.path.join(output_root, \"train\")\n",
    "output_test = os.path.join(output_root, \"test\")\n",
    "\n",
    "os.makedirs(output_train, exist_ok=True)\n",
    "os.makedirs(output_test, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6849e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"trainCNN.csv\"):\n",
    "    new_train_df = generate_regression_dataset(train_df, output_train, train_data_path, type = \"train\", do_segment=False)\n",
    "    new_train_df[\"RootVolume\"] = new_train_df.groupby(\"FolderName\")[\"RootVolume\"].transform(\"mean\")\n",
    "else:\n",
    "    new_train_df = pd.read_csv(\"trainCNN.csv\")\n",
    "    \n",
    "if not os.path.exists(\"testCNN.csv\"):\n",
    "    new_test_df = generate_regression_dataset(test_df, output_test, test_data_path, type = \"test\")\n",
    "else:\n",
    "    new_test_df = pd.read_csv(\"testCNN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e559ecb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN      Unnamed: 0                ID  FolderName  PlantNumber Side  Start  End  \\\n",
      "56           56  ID_470797_Ayxwed  Dz9lpsl9ae            3    L     37   46   \n",
      "8             8  ID_216014_Djn5n6  Vinlgebupo            2    L     23   29   \n",
      "173         173  ID_769193_Hzpyfs  Vwsx0beaxb            4    L     27   39   \n",
      "385         385  ID_747792_Ofa0wh  Izbgyxre0g            6    R     22   33   \n",
      "366         366  ID_361716_Sufszh  Bb02c5k7wm            2    L     22   31   \n",
      "..          ...               ...         ...          ...  ...    ...  ...   \n",
      "323         323  ID_969350_G9jqgp  Izbgyxre0g            4    L     24   37   \n",
      "192         192  ID_258788_Bsotub  Xrrcqvdbkw            6    R     27   36   \n",
      "117         117  ID_309524_Tsywg8  Kjvcz6bjfj            4    R     26   39   \n",
      "47           47  ID_456912_Blrqzy  Ah4ubi4ggi            3    L     42   49   \n",
      "172         172  ID_858876_Vraxy7  Xdi1ipcemf            2    R     32   38   \n",
      "\n",
      "     RootVolume            Genotype  Stage  WasSegmented  \\\n",
      "56          2.5             TMEB419  Early         False   \n",
      "8           0.4           IBA980581  Early         False   \n",
      "173         2.9           IBA980581  Early         False   \n",
      "385         3.7           IBA154810  Early         False   \n",
      "366         1.8             TMEB693  Early         False   \n",
      "..          ...                 ...    ...           ...   \n",
      "323         1.3           IBA154810  Early         False   \n",
      "192         2.2           IBA154810  Early         False   \n",
      "117         2.1           IBA980581  Early         False   \n",
      "47          2.3  IITA-TMS-IBA000070  Early         False   \n",
      "172         4.3  IITA-TMS-IBA000070  Early         False   \n",
      "\n",
      "                                ImageSegments  Width  \n",
      "56   merged_images/train/ID_470797_Ayxwed.png    862  \n",
      "8    merged_images/train/ID_216014_Djn5n6.png    849  \n",
      "173  merged_images/train/ID_769193_Hzpyfs.png    904  \n",
      "385  merged_images/train/ID_747792_Ofa0wh.png    942  \n",
      "366  merged_images/train/ID_361716_Sufszh.png    928  \n",
      "..                                        ...    ...  \n",
      "323  merged_images/train/ID_969350_G9jqgp.png    947  \n",
      "192  merged_images/train/ID_258788_Bsotub.png    952  \n",
      "117  merged_images/train/ID_309524_Tsywg8.png    910  \n",
      "47   merged_images/train/ID_456912_Blrqzy.png    903  \n",
      "172  merged_images/train/ID_858876_Vraxy7.png    978  \n",
      "\n",
      "[308 rows x 13 columns]\n",
      "TEST      Unnamed: 0                ID  FolderName  PlantNumber Side  Start  End  \\\n",
      "260         260  ID_884849_Bmtyoy  Pfp24vx905            3    R     27   34   \n",
      "320         320  ID_747419_Zihzns  F1p0lhe1ij            4    R     30   37   \n",
      "144         144  ID_355808_Brk59j  Mrw7chmalv            6    L     18   23   \n",
      "52           52  ID_211500_Ndgm1d  Vbkivqphuz            5    L     20   32   \n",
      "210         210  ID_321332_Jptlgu  Pw4ytibfql            4    R     28   35   \n",
      "..          ...               ...         ...          ...  ...    ...  ...   \n",
      "302         302  ID_794803_Tvlbyb  Rxxe9bh6qn            7    L     31   40   \n",
      "327         327  ID_688192_Bdosyn  L8w7zu7wek            3    R     27   33   \n",
      "329         329  ID_271070_Fsmcir  Hc3b9gicdo            3    R     29   38   \n",
      "246         246  ID_219723_Urg3bc  Puya1uaaln            6    R     16   37   \n",
      "344         344  ID_467568_Bzuthn  Toaefqwoli            3    L     37   47   \n",
      "\n",
      "     RootVolume            Genotype  Stage  WasSegmented  \\\n",
      "260        1.70             TMEB419  Early         False   \n",
      "320        2.10  IITA-TMS-IBA000070  Early         False   \n",
      "144        3.30           IBA154810  Early         False   \n",
      "52         2.10             TMEB693  Early         False   \n",
      "210        1.50             TMEB419  Early         False   \n",
      "..          ...                 ...    ...           ...   \n",
      "302        0.01           IBA980581  Early         False   \n",
      "327        2.90  IITA-TMS-IBA000070  Early         False   \n",
      "329        3.10  IITA-TMS-IBA000070  Early         False   \n",
      "246        2.10             TMEB419  Early         False   \n",
      "344        0.50             TMEB419  Early         False   \n",
      "\n",
      "                                ImageSegments  Width  \n",
      "260  merged_images/train/ID_884849_Bmtyoy.png   1022  \n",
      "320  merged_images/train/ID_747419_Zihzns.png   1036  \n",
      "144  merged_images/train/ID_355808_Brk59j.png    915  \n",
      "52   merged_images/train/ID_211500_Ndgm1d.png    955  \n",
      "210  merged_images/train/ID_321332_Jptlgu.png    975  \n",
      "..                                        ...    ...  \n",
      "302  merged_images/train/ID_794803_Tvlbyb.png    963  \n",
      "327  merged_images/train/ID_688192_Bdosyn.png    963  \n",
      "329  merged_images/train/ID_271070_Fsmcir.png    983  \n",
      "246  merged_images/train/ID_219723_Urg3bc.png    917  \n",
      "344  merged_images/train/ID_467568_Bzuthn.png    875  \n",
      "\n",
      "[78 rows x 13 columns]\n",
      "new_test_df      Unnamed: 0                ID  FolderName  PlantNumber Side  Start  End  \\\n",
      "0             0  ID_208667_Hnkl8q  L5l1h3kekg            7    L     38   50   \n",
      "1             1  ID_285249_Jnjvav  Wgutyon8uu            6    R     23   37   \n",
      "2             2  ID_697947_Yec6bd  Mylwjeq6tq            3    R     19   42   \n",
      "3             3  ID_534638_X3j91f  Pfp24vx905            2    R     27   34   \n",
      "4             4  ID_929298_Xvymuz  Mrw7chmalv            4    R     30   43   \n",
      "..          ...               ...         ...          ...  ...    ...  ...   \n",
      "125         125  ID_652025_Ecubfg  L8w7zu7wek            4    L     33   51   \n",
      "126         126  ID_456856_Iucagp  Klhqlr0ako            2    L     38   47   \n",
      "127         127  ID_163551_Alfdb5  Vlqr6qhbqk            3    L     48   55   \n",
      "128         128  ID_947929_Qsuqln  Pfp24vx905            5    R     27   34   \n",
      "129         129  ID_225470_Hju47r  Qhqftdiz4q            6    L     28   38   \n",
      "\n",
      "               Genotype  Stage  WasSegmented  \\\n",
      "0    IITA-TMS-IBA000070  Early         False   \n",
      "1               TMEB419  Early         False   \n",
      "2             IBA980581  Early         False   \n",
      "3               TMEB419  Early         False   \n",
      "4             IBA154810  Early         False   \n",
      "..                  ...    ...           ...   \n",
      "125  IITA-TMS-IBA000070  Early         False   \n",
      "126             TMEB693  Early         False   \n",
      "127           IBA154810  Early         False   \n",
      "128             TMEB419  Early         False   \n",
      "129  IITA-TMS-IBA000070  Early         False   \n",
      "\n",
      "                               ImageSegments  Width  \n",
      "0    merged_images/test/ID_208667_Hnkl8q.png    978  \n",
      "1    merged_images/test/ID_285249_Jnjvav.png   1050  \n",
      "2    merged_images/test/ID_697947_Yec6bd.png   1006  \n",
      "3    merged_images/test/ID_534638_X3j91f.png   1022  \n",
      "4    merged_images/test/ID_929298_Xvymuz.png    910  \n",
      "..                                       ...    ...  \n",
      "125  merged_images/test/ID_652025_Ecubfg.png    964  \n",
      "126  merged_images/test/ID_456856_Iucagp.png    959  \n",
      "127  merged_images/test/ID_163551_Alfdb5.png    952  \n",
      "128  merged_images/test/ID_947929_Qsuqln.png   1022  \n",
      "129  merged_images/test/ID_225470_Hju47r.png    905  \n",
      "\n",
      "[130 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(new_train_df, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c507f538",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RootVolumeDataset(train, train_transform)\n",
    "test_dataset = RootVolumeDataset(test, test_transform)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "model = RootVolumeRegressor()\n",
    "\n",
    "if os.path.exists(\"cnn_models/model_no_seg.ckpt\"):\n",
    "    state_dict = torch.load(\"cnn_models/model_no_seg.ckpt\")['state_dict']\n",
    "    model.load_state_dict(state_dict)\n",
    "else:\n",
    "    trainer = L.Trainer(max_epochs = 20)\n",
    "    trainer.fit(model, train_dataloader)\n",
    "    os.makedirs(\"cnn_models\", exist_ok=True)\n",
    "    trainer.save_checkpoint(\"cnn_models/model_no_seg.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a2caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader <torch.utils.data.dataloader.DataLoader object at 0x7320042fa6f0>\n",
      "dummy_input tensor([[[[-0.3215, -1.7820, -0.3430,  ...,  1.9012, -0.0707,  0.6688],\n",
      "          [ 2.6402,  0.7574, -1.9474,  ..., -0.3053,  0.6065,  0.8220],\n",
      "          [ 0.6119,  0.4890,  1.2862,  ...,  0.5157,  0.2814,  0.8123],\n",
      "          ...,\n",
      "          [ 1.3485,  0.3681, -1.8600,  ...,  0.5698,  2.2335,  0.3354],\n",
      "          [-0.5802,  0.3578, -0.4872,  ...,  1.8528,  0.1232,  0.0520],\n",
      "          [ 1.2476, -0.5402,  0.2775,  ...,  1.1420,  0.3478,  0.4237]],\n",
      "\n",
      "         [[ 1.0047, -1.0976,  1.0387,  ..., -0.6027,  1.6541,  0.6535],\n",
      "          [-0.9187,  0.4677,  0.7053,  ...,  0.6562, -0.9255,  0.6144],\n",
      "          [-0.2071, -0.4263, -0.5910,  ...,  0.8113, -0.4720, -0.9351],\n",
      "          ...,\n",
      "          [ 0.3333,  1.3945,  0.3191,  ...,  0.3988, -0.1370,  0.5948],\n",
      "          [ 1.0884, -0.0552,  0.6049,  ..., -1.1653, -0.5788,  1.1405],\n",
      "          [-0.0938, -0.0118, -1.2353,  ..., -0.4395,  1.8589,  0.8068]],\n",
      "\n",
      "         [[ 1.2452,  1.8404,  0.5555,  ...,  0.7306,  0.4709, -0.5964],\n",
      "          [ 0.5006,  0.1005, -0.5525,  ..., -0.6151, -1.8627,  0.0737],\n",
      "          [-0.7556,  0.0338, -0.3467,  ...,  0.7192, -0.5398,  0.6390],\n",
      "          ...,\n",
      "          [ 0.1231,  0.9333,  0.2501,  ..., -0.1497, -1.2003,  0.6243],\n",
      "          [-0.6185,  1.4801, -1.2303,  ..., -0.0109,  0.0907, -0.6551],\n",
      "          [-0.8903, -0.4031,  0.1189,  ...,  0.3776, -0.6439, -0.9141]]]])\n"
     ]
    }
   ],
   "source": [
    "model = RootVolumeRegressor()\n",
    "\n",
    "# Load state dict\n",
    "if os.path.exists(\"cnn_models/model_no_seg.pt\"):\n",
    "    state_dict = torch.load(\"cnn_models/model_no_seg.pt\")['state_dict']\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    dummy_input = torch.randn(1, 3, 128, 128)\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        \"./cnn_models/model_no_seg.onnx\",\n",
    "        export_params=True,\n",
    "        opset_version=14,\n",
    "        do_constant_folding=True,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"output\"],\n",
    "        dynamic_axes={\n",
    "            \"input\": {0: \"batch_size\"},\n",
    "            \"output\": {0: \"batch_size\"}\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2332ec0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(\"cnn_models/model_no_seg.pt\")['state_dict']\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0cb912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input torch.Size([16, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([16]) torch.float32\n",
      "outputs torch.Size([16, 1]) torch.float32\n",
      "Input torch.Size([16, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([16]) torch.float32\n",
      "outputs torch.Size([16, 1]) torch.float32\n",
      "Input torch.Size([16, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([16]) torch.float32\n",
      "outputs torch.Size([16, 1]) torch.float32\n",
      "Input torch.Size([16, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([16]) torch.float32\n",
      "outputs torch.Size([16, 1]) torch.float32\n",
      "Input torch.Size([14, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([14]) torch.float32\n",
      "outputs torch.Size([14, 1]) torch.float32\n",
      "[     1.9505      1.8192       2.353       2.189      1.9886      2.1922      2.1927      1.7606       1.867      2.0731      2.2539      1.9707      1.9904      1.9205      2.1261      2.2658      1.9049      1.9366      1.7559      2.1192      1.6729       2.794      2.1179      2.2108      1.9178      1.9479\n",
      "      2.2986      2.1261      2.6299      2.4175      2.1015      1.6691      1.9731      1.9174      1.9687      1.9006      1.7606      2.0943      3.7035      1.7058      2.6267       2.232      2.0291      1.9982      1.8331      2.1576      2.1231      1.8108       1.939      1.9651      2.8584      2.0515\n",
      "      2.2623      1.9775      1.8272      1.6679      1.9848      1.9785      2.2108      2.4146      2.0291      1.9436      2.0035      2.0324      2.1179       2.232      2.1428      2.1428      1.9731      2.5902      2.7058      2.3108      2.0467       1.939      1.9687      1.8735      2.2249      1.8466]\n",
      "[        1.7         2.1         3.3         2.1         1.5         2.6         2.2         0.5         1.8         1.8         1.7         4.2         2.1         1.8         0.8         0.9           3         2.3         0.8         1.9         0.2         0.9         1.8         0.3         1.5         2.2\n",
      "         2.2         2.9         2.3         2.3         2.1         1.4         0.3         6.2         4.5         1.5         0.1         1.7         4.9         0.7         2.8         1.9         4.5         6.2         2.1         2.1         1.9         6.3         0.8         2.3         0.8         2.6\n",
      "         1.8         1.3         0.4         2.5         3.7         1.4         0.8         0.9         2.3         5.8         0.2         2.3         3.1         0.8         0.8         1.4         0.1         2.2         3.4         1.7         2.9        0.01         2.9         3.1         2.1         0.5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float32(1.4135247)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, target = get_model_preds(model, test_dataloader)\n",
    "calculate_rmse(preds, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f517f7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input torch.Size([16, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([16]) torch.float32\n",
      "outputs torch.Size([16, 1]) torch.float32\n",
      "Input torch.Size([16, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([16]) torch.float32\n",
      "outputs torch.Size([16, 1]) torch.float32\n",
      "Input torch.Size([16, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([16]) torch.float32\n",
      "outputs torch.Size([16, 1]) torch.float32\n",
      "Input torch.Size([16, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([16]) torch.float32\n",
      "outputs torch.Size([16, 1]) torch.float32\n",
      "Input torch.Size([14, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([14]) torch.float32\n",
      "outputs torch.Size([14, 1]) torch.float32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>FolderName</th>\n",
       "      <th>PlantNumber</th>\n",
       "      <th>Side</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>RootVolume</th>\n",
       "      <th>Genotype</th>\n",
       "      <th>Stage</th>\n",
       "      <th>WasSegmented</th>\n",
       "      <th>ImageSegments</th>\n",
       "      <th>Width</th>\n",
       "      <th>Preds</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>260</td>\n",
       "      <td>ID_884849_Bmtyoy</td>\n",
       "      <td>Pfp24vx905</td>\n",
       "      <td>3</td>\n",
       "      <td>R</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>1.7</td>\n",
       "      <td>TMEB419</td>\n",
       "      <td>Early</td>\n",
       "      <td>False</td>\n",
       "      <td>merged_images/train/ID_884849_Bmtyoy.png</td>\n",
       "      <td>1022</td>\n",
       "      <td>1.959673</td>\n",
       "      <td>15.274888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>320</td>\n",
       "      <td>ID_747419_Zihzns</td>\n",
       "      <td>F1p0lhe1ij</td>\n",
       "      <td>4</td>\n",
       "      <td>R</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>2.1</td>\n",
       "      <td>IITA-TMS-IBA000070</td>\n",
       "      <td>Early</td>\n",
       "      <td>False</td>\n",
       "      <td>merged_images/train/ID_747419_Zihzns.png</td>\n",
       "      <td>1036</td>\n",
       "      <td>1.828650</td>\n",
       "      <td>12.921402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>144</td>\n",
       "      <td>ID_355808_Brk59j</td>\n",
       "      <td>Mrw7chmalv</td>\n",
       "      <td>6</td>\n",
       "      <td>L</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>3.3</td>\n",
       "      <td>IBA154810</td>\n",
       "      <td>Early</td>\n",
       "      <td>False</td>\n",
       "      <td>merged_images/train/ID_355808_Brk59j.png</td>\n",
       "      <td>915</td>\n",
       "      <td>2.352954</td>\n",
       "      <td>28.698372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>ID_211500_Ndgm1d</td>\n",
       "      <td>Vbkivqphuz</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>2.1</td>\n",
       "      <td>TMEB693</td>\n",
       "      <td>Early</td>\n",
       "      <td>False</td>\n",
       "      <td>merged_images/train/ID_211500_Ndgm1d.png</td>\n",
       "      <td>955</td>\n",
       "      <td>2.190696</td>\n",
       "      <td>4.318885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>210</td>\n",
       "      <td>ID_321332_Jptlgu</td>\n",
       "      <td>Pw4ytibfql</td>\n",
       "      <td>4</td>\n",
       "      <td>R</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>1.5</td>\n",
       "      <td>TMEB419</td>\n",
       "      <td>Early</td>\n",
       "      <td>False</td>\n",
       "      <td>merged_images/train/ID_321332_Jptlgu.png</td>\n",
       "      <td>975</td>\n",
       "      <td>1.978499</td>\n",
       "      <td>31.899929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                ID  FolderName  PlantNumber Side  Start  End  \\\n",
       "260         260  ID_884849_Bmtyoy  Pfp24vx905            3    R     27   34   \n",
       "320         320  ID_747419_Zihzns  F1p0lhe1ij            4    R     30   37   \n",
       "144         144  ID_355808_Brk59j  Mrw7chmalv            6    L     18   23   \n",
       "52           52  ID_211500_Ndgm1d  Vbkivqphuz            5    L     20   32   \n",
       "210         210  ID_321332_Jptlgu  Pw4ytibfql            4    R     28   35   \n",
       "\n",
       "     RootVolume            Genotype  Stage  WasSegmented  \\\n",
       "260         1.7             TMEB419  Early         False   \n",
       "320         2.1  IITA-TMS-IBA000070  Early         False   \n",
       "144         3.3           IBA154810  Early         False   \n",
       "52          2.1             TMEB693  Early         False   \n",
       "210         1.5             TMEB419  Early         False   \n",
       "\n",
       "                                ImageSegments  Width     Preds       MAPE  \n",
       "260  merged_images/train/ID_884849_Bmtyoy.png   1022  1.959673  15.274888  \n",
       "320  merged_images/train/ID_747419_Zihzns.png   1036  1.828650  12.921402  \n",
       "144  merged_images/train/ID_355808_Brk59j.png    915  2.352954  28.698372  \n",
       "52   merged_images/train/ID_211500_Ndgm1d.png    955  2.190696   4.318885  \n",
       "210  merged_images/train/ID_321332_Jptlgu.png    975  1.978499  31.899929  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "preds, target = get_model_preds(model, test_dataloader)\n",
    "targets=target\n",
    "preds = np.array(preds) if not isinstance(preds, np.ndarray) else preds\n",
    "targets = np.array(targets) if not isinstance(targets, np.ndarray) else targets\n",
    "res = []\n",
    "for i in range(len(targets)):\n",
    "    target = targets[i]\n",
    "    pred = preds[i]\n",
    "    if abs(target) < 1e-3:\n",
    "        res.append(0)\n",
    "    else:\n",
    "        res.append((np.abs(pred - target) / target) * 100)\n",
    "\n",
    "\n",
    "test[\"Preds\"] = preds\n",
    "test[\"MAPE\"] = res\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da061aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46facfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArYAAAINCAYAAADLDjxaAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAR9RJREFUeJzt3XtclHXe//H3cFQUD0CAeD7gAQ94QEjUVm8zs9ai2tZftbekW7vWkBrbwR61am5ld1tm1pRrrbG2ubHrvWqHzXIxM7U8ZFotamBU5gFRQxA3QGZ+f3gzG4E4AzNzDde8no8HjwdzXRfX9Zkvmu++8z1YHA6HQwAAAEALF2R0AQAAAIAnEGwBAABgCgRbAAAAmALBFgAAAKZAsAUAAIApEGwBAABgCgRbAAAAmALBFgAAAKYQYnQBRrPb7Tpy5IgiIyNlsViMLgcAAAA/4nA4VF5eroSEBAUFXbhfNuCD7ZEjR9S1a1ejywAAAMBFHDp0SF26dLng+YAPtpGRkZLON1S7du28+qzq6mq9++67uuKKKxQaGurVZwUy2tn7aGPfoJ29jzb2DdrZN8zczmVlZerataszt11IwAfb2uEH7dq180mwjYiIULt27Uz3B86f0M7eRxv7Bu3sfbSxb9DOvhEI7XyxYaNMHgMAAIApBGywtdlsSkpK0siRI40uBQAAAB4QsMHWarUqPz9fO3fuNLoUAAAAeEDABlsAAACYC8EWAAAApkCwBQAAgCkQbAEAAGAKBFsAAACYAsEWAAAApkCwBQAAgCkQbAEAAGAKBFsAAACYAsEWAAAApkCwBQAAgCkQbAEAAGAKBFsAAACYQsAGW5vNpqSkJI0cOdJnz3Q4HJKkVz/6WlsLTzhfAwAAoPkCNtharVbl5+dr586dPnvm9qJTkqRF6/dr2ood2lZ40mfPBgAAMLuADbZGOHj8jPP7GrtDBSXlBlYDAABgLgRbH+od29b5fXCQRYmxkQZWAwAAYC4hRhcQSNJ6Runt/dIDk/srMb6D0ntHG10SAACAaRBsfchisUiSbknrrtDQUIOrAQAAMBeGIgAAAMAUCLYAAAAwBYItAAAATIFgCwAAAFMg2AIAAMAUCLYAAAAwBYItAAAATIFgCwAAAFMg2AIAAMAUCLYAAAAwBYItAAAATIFgCwAAAFMg2AIAAMAUCLYAAAAwBYItAAAATME0wfbs2bPq3r277rnnHqNLAQAAgAFME2wfffRRXXrppUaXAQAAAIOYItgWFBRo//79mjx5stGlAAAAwCCGB9vNmzdrypQpSkhIkMVi0dq1a+tdY7PZ1KNHD7Vq1UppaWnasWNHnfP33HOPFi1a5KOKAQAA4I9CjC6goqJCycnJmjFjhq6//vp653Nzc5Wdna1ly5YpLS1NS5Ys0aRJk3TgwAHFxsZq3bp16tu3r/r27att27Zd9HmVlZWqrKx0vi4rK5MkVVdXq7q62nNvrAG19/f2cwId7ex9tLFv0M7eRxv7Bu3sG2ZuZ1ffk8XhcDi8XIvLLBaL1qxZo4yMDOextLQ0jRw5Us8995wkyW63q2vXrrrrrrs0d+5cPfDAA/rzn/+s4OBgnTlzRtXV1frNb36jefPmNfiMBQsW6OGHH653fNWqVYqIiPDK+wIAAEDTnT17VjfffLNOnz6tdu3aXfA6vw62VVVVioiI0OrVq+uE3czMTJWWlmrdunV1fj4nJ0eff/65nnzyyQs+o6Ee265du+rEiRONNpQnVFdXa8OGDZo4caJCQ0O9+qxARjt7H23sG7Sz99HGvkE7+4aZ27msrEwxMTEXDbaGD0VozIkTJ1RTU6O4uLg6x+Pi4rR///4m3TM8PFzh4eH1joeGhvrsD4EvnxXIaGfvo419g3b2PtrYN2hn3zBjO7v6fvw62Lrr1ltvNboEAAAAGMTwVREaExMTo+DgYBUXF9c5XlxcrPj4+Gbd22azKSkpSSNHjmzWfQAAAOAf/DrYhoWFacSIEcrLy3Mes9vtysvL06hRo5p1b6vVqvz8fO3cubO5ZQIAAMAPGD4U4cyZMyosLHS+Lioq0p49exQVFaVu3bopOztbmZmZSklJUWpqqpYsWaKKigpNnz7dwKoBAADgbwwPtrt27dL48eOdr7OzsyWdX/kgJydHU6dOVUlJiebNm6djx45p6NChWr9+fb0JZQAAAAhshgfbcePG6WIrjmVlZSkrK8tHFQEAAKAl8usxtt7E5DEAAABzCdhgy+QxAAAAcwnYYAsAAABzIdgCAADAFAi2AAAAMIWADbZMHgMAADCXgA22TB4DAAAwl4ANtgAAADAXgi0AAABMgWALAAAAUyDYAgAAwBQCNtiyKgIAAIC5BGywZVUEAAAAcwnYYAsAAABzIdgCAADAFAi2AAAAMAWCLQAAAEyBYAsAAABTCNhgy3JfAAAA5hKwwZblvgAAAMwlYIMtAAAAzIVgCwAAAFMg2AIAAMAUCLYAAAAwBYItAAAATIFgCwAAAFMI2GDLOrYAAADmErDBlnVsAQAAzCVggy0AAADMhWALAAAAUyDYAgAAwBQItgAAADAFgi0AAABMgWALAAAAUyDYAgAAwBQItgAAADAFgi0AAABMIWCDLVvqAgAAmEvABlu21AUAADCXgA22AAAAMBeCLQAAAEyBYAsAAABTINgCAADAFAi2AAAAMAWCLQAAAEyBYAsAAABTINgCAADAFAi2AAAAMAWCLQAAAEyBYAsAAABTINgCAADAFAi2AAAAMIUQowswis1mk81mU01NjdGlODkcDm07eFIFxeVKjItUeu9oWSwWo8sCAABoEQI22FqtVlmtVpWVlal9+/ZGlyNJ2nbwpKat2KEau0PBQRatnJ6q0YkxRpcFAADQIjAUwY8UFJerxu6QJNXYHSooKTe4IgAAgJaDYOtHEuMiFRx0fuhBcJBFibGRBlcEAADQcgTsUAR/lN47Wiunp6qgpFyJsefH2AIAAMA19Nj6G4skh9FFAAAAtDz02PoRJo8BAAA0HT22foTJYwAAAE1HsPUjTB4DAABoOoYi+BEmjwEAADQdwdaPWCwWjU6MYVwtAABAEzAUAQAAAKZAsAUAAIApEGwBAABgCgRbAAAAmALBFgAAAKZAsAUAAIApEGwBAABgCgRbAAAAmALBFgAAAKbQ4oNtaWmpUlJSNHToUA0aNEgvvvii0SUBAADAAC1+S93IyEht3rxZERERqqio0KBBg3T99dcrOjra6NIAAADgQy2+xzY4OFgRERGSpMrKSjkcDjkcDoOrAgAAgK8ZHmw3b96sKVOmKCEhQRaLRWvXrq13jc1mU48ePdSqVSulpaVpx44ddc6XlpYqOTlZXbp00b333quYmBgfVQ8AAAB/YXiwraioUHJysmw2W4Pnc3NzlZ2drfnz52v37t1KTk7WpEmTdPz4cec1HTp00N69e1VUVKRVq1apuLjYV+UDAADATxg+xnby5MmaPHnyBc8vXrxYt99+u6ZPny5JWrZsmd566y2tWLFCc+fOrXNtXFyckpOT9cEHH+hnP/tZg/errKxUZWWl83VZWZkkqbq6WtXV1c19O42qvb+3nxPoaGfvo419g3b2PtrYN2hn3zBzO7v6niwOPxqQarFYtGbNGmVkZEiSqqqqFBERodWrVzuPSVJmZqZKS0u1bt06FRcXKyIiQpGRkTp9+rRGjx6tv/zlLxo8eHCDz1iwYIEefvjhesdXrVrlHKsLAAAA/3H27FndfPPNOn36tNq1a3fB6wzvsW3MiRMnVFNTo7i4uDrH4+LitH//fknS119/rV/96lfOSWN33XXXBUOtJD3wwAPKzs52vi4rK1PXrl11xRVXNNpQnlBdXa0NGzZo4sSJCg0N9eqzAhnt7H20sW/Qzt5HG/sG7ewbZm7n2k/YL8avg60rUlNTtWfPHpevDw8PV3h4eL3joaGhPvtD0JxnORwObTt4UgXF5UqMi1R672hZLBYPV2gOvvydBira2DdoZ++jjX2DdvYNM7azq++nWcH2rbfe0qZNm1RTU6PRo0frhhtuaM7t6omJiVFwcHC9yWDFxcWKj4/36LNaim0HT2raih2qsTsUHGTRyumpGp3IKhAAAABNXhXht7/9re677z5ZLBY5HA7dfffduuuuuzxZm8LCwjRixAjl5eU5j9ntduXl5WnUqFHNurfNZlNSUpJGjhzZ3DJ9qqC4XDX288Oia+wOFZSUG1wRAACAf3C5x3bXrl1KSUlxvs7NzdXevXvVunVrSdKtt96qcePG6dlnn3WrgDNnzqiwsND5uqioSHv27FFUVJS6deum7OxsZWZmKiUlRampqVqyZIkqKiqcqyQ0ldVqldVqVVlZmdq3b9+se/lSYlykgoMszh7bxNhIo0sCAADwCy4H25kzZ2rMmDF67LHHFBERoV69eumpp57SjTfeqKqqKr3wwgvq27ev2wXs2rVL48ePd76undiVmZmpnJwcTZ06VSUlJZo3b56OHTumoUOHav369fUmlAWK9N7RWjk9VQUl5UqMPT/GFgAAAG4MRdi+fbs6deqk4cOH64033tCKFSv0ySefKD09XWPHjtW3336rVatWuV3AuHHjnCsa/PArJyfHeU1WVpa+/vprVVZWavv27UpLS3P7OWZhsVg0OjFGt6b31Og+MUwcAwAA+D8u99gGBwfr/vvv14033qg77rhDbdq00XPPPaeEhARv1uc1NptNNptNNTU1RpcCAAAAD3B78livXr30zjvv6LrrrtNll112wa1w/Z3ValV+fr527txpdCkAAADwAJeDbWlpqe677z5NmTJFDz30kK677jpt375dO3fu1KWXXqrPPvvMm3Xi/zgcDm0tPKGcrUXaWnhCfrRxHAAAgKFcDraZmZnavn27rr76ah04cEB33HGHoqOjlZOTo0cffVRTp07V/fff781aof+sY7vgjXxNW7FD2wpPGl0SAACAX3A52G7cuFF//OMfNXPmTL322mvasmWL89yECRO0e/duBQcHe6VI/Afr2AIAADTM5WCbmJio5cuX64svvtCyZcvUvXv3OudbtWqlxx57zOMFektL3aChdh1bSaxjCwAA8AMur4qwYsUK3XbbbbLZbBo6dKheeuklb9bldS11gwbWsQUAAGiYy8F26NCh2rVrlzdrgQtq17EdnRhzwWscDoe2HTypguJyJcadD7+sdwsAAMzO5WCLlqN2glnttrsrp6c2GoQBAADMwO11bOH/mGAGAAACEcHWhJhgBgAAAlHADkUw85a6TDADAACBKGB7bE2/pa5FEpuSAQCAAOLRHtuFCxdq/PjxGjt2rCdvCzcxeQwAAAQij/bYvvzyy5o0aZKmTJniydvCTUweAwAAgcijPbZFRUX697//rffee8+Tt4WbaieP1fbYMnkMAAAEAo9PHmvdurWuuuoqT98WbmDyGAAACERNDrZnz57VN998o6qqqjrHhwwZ0uyi0Dyu7E4GAABgNm4H25KSEk2fPl1vv/12g+dbyvJZZl7uCwAAIBC5PXlszpw5Ki0t1fbt29W6dWutX79ef/rTn5SYmKjXX3/dGzV6hemX+wIAAAgwbvfYbty4UevWrVNKSoqCgoLUvXt3TZw4Ue3atdOiRYt09dVXe6NOAAAAoFFu99hWVFQoNjZWktSxY0eVlJRIkgYPHqzdu3d7tjoAAADARW4H2379+unAgQOSpOTkZP3hD3/Q4cOHtWzZMnXq1MnjBQIAAACucHsowuzZs3X06FFJ0vz583XllVfq1VdfVVhYmHJycjxdHwAAAOASt4PtL37xC+f3I0aM0Ndff639+/erW7duiolheSkAAAAYo9lb6kZERGj48OGKiYnR8ePHPVETAAAA4Da3g+28efMaPP7qq69q4MCBzS4IAAAAaAq3g21OTo5mz57tfH38+HFlZGRo9uzZevrppz1anDfZbDYlJSVp5MiRRpcCAAAAD3B7jO0HH3ygiRMnqrS0VBMnTtTs2bM1ZswYff7554qPj/dGjV5htVpltVpVVlam9u3bG10OAAAAmsntYNu9e3dt3rxZV1xxhf785z/rD3/4g2677TZv1AYvcjgc2nbwpAqKy5UYF6n03tGyWCxGlwUAANBkTZo8Fh8fr82bNystLU25ubn697//7em64GXbDp7UtBU7tOCNfE1bsUPbCk8aXRIAAECzuN1j27FjR2fPXnV1tXMnstDQUEnSqVOnPFshvKKguFw1dockqcbuUEFJuUYnslwbAABoudwOtkuWLPFCGfC1xLhIBQdZVGN3KDjIosTYSKNLAgAAaBa3g21mZqY36oCPpfeO1srpqSooKVdi7PkxtgAAAC2Z28FWkiorK/Xqq68qPz9fFotFAwcO1E033aTw8HBP1wcvsVgsGp0Yw/ADAABgGhedPHbu3Dl16dJFJSUlkqT8/HwlJibqnnvu0ccff6xdu3YpOztbffv21f79+71eMAAAANCQiwbbkJAQnTlzRuXl5ZKk2bNnKyUlRd98843ee+89vffee/r66681fPjwOhs3AAAAAL7k0lCEmJgYnT17VpK0bds27dixQ23btnWej4yM1MKFCzVq1CjvVOkFNptNNptNNTU1RpcCAAAAD3BpHdthw4bp7bffliR16NBBpaWl9a45ffq0wsLCPFqcN1mtVuXn52vnzp1GlwIAAAAPcCnYWq1WPfLII9q4caMyMjL061//Wtu3b5fD4ZDD4dBHH32kmTNn6uqrr/Z2vfAhh8OhrYUnlLO1SFsLT8jhcBhdEgAAwAW5NBRh3Lhxev755/Wzn/1MrVu31tGjR5Wenq6QkPM/fu7cOV155ZV65plnvFosfKt2d7LatW5XTk9lFQUAAOC3XF7u65ZbblFGRoY++OADlZSUyG63Szq/E1n//v3Vt29frxUJY/hydzKHw6FtB0+qoLhciXHn19Wt3eEOAADAFW6tY9umTRtdeeWV3qoFfiYxru2Pdidre/EfaiJ6hwEAQHO5vUHD0qVLGz0/a9asJhcD/xJksWhqShdVVNWoTXiIguS9HlRf9g4DAABzcjvYzpkzRxEREYqNja03mchisRBsTeTAsXKt2nHI+bpvXFuN6uOdsJkYF/mj3uFIrzwHAACYl9vB9sEHH9Qzzzyjyy+/XL/73e8UFxfnjbrgB3wZNtN7R2vl9FQVlJQrMfb8GFsAAAB3uLTc1w/97ne/0759+1RVVaV+/frp0UcfVWVlpTdqg8Fqw+aCa5K0ckaqV8OmxWLR6MQY3ZreU6P7xDBxDAAAuM3tYCtJnTt3Vk5OjjZu3Ki8vDz16dNHK1eu9HRtMBhhEwAAtCRuD0X49NNP//PDISFasmSJ1q1bp6ysLD3zzDP6+OOPPVogAAAA4Aq3g+3QoUNlsVicE8d++P2ePXs8WhzwQ6x1CwAAGuN2sC0qKvJGHcBFsdYtAABojNvBtnv37t6oA7go1roFAACNcTvYvv76642ev+aaa5pcDNAY1roFAACNcTvYZmRkXPBcUFCQzp0715x6fMZms8lms6mmpsboUuAi1roFAACNcTvY2u32Bo9///33ioiIaHZBvmK1WmW1WlVWVqb27dsbXQ5cULv8GMMPAABAQ9wOthdisViYoY4ms9vteuPTozpwrFz94iM1ZUgnBQU1aZllAAAQoDwWbIHmeOPTo8r+617n+Fk5pGuHdTa6LAAA0IK4HWx79uzZYM9s7Vq2QFN8WXJGU1O6qqLqnNqEhajo5Jl617COLQAAaIzbwXbOnDkNHq+urtb999/f3HoQoDp3jNBz7x109tguum5wvWtYxxYAADTG7WA7e/bsBo9///33BFs0WXHZ93XWqD1e/n29a1jHFgAANMZjs3P4SBjNERURen5sraTgIIs6tgmtd03tOra117COLQAA+CG3e2yXLl3a4PGWsn4t/FOvS9pqakoXVVTVqE14iHrFtK13zaheUVp8Y7K+OF6uvnGRGtUryoBKAQCAv3I72D799NMXPNetW7dmFYPAdWmvaNntcm6+cGmv+psvfPjlKWX/7T8rJ8S0CWcoAgAAcHI72BYVFXmjDpiYy6sZWCQ1srgGY2wBAEBjmrWObe0SX4yvRWNcWc3AlWtqx9jWXsMYWwAA8ENNmjy2cuVKDR48WK1bt1br1q01ZMgQvfLKK56uDSbRUE9rU65J7x2tldNTteCaJK2ckar03vWHKwAAgMDldo/t4sWL9dvf/lZZWVkaPXq0JGnLli2aOXOmTpw4obvvvtvjRaJlc6Wn1ZVrLBaLRifGMPwAAAA0yO1g++yzz+qFF17QtGnTnMeuueYaDRw4UAsWLCDYop7antbaiWEN9bS6cg0AAEBj3A62R48eVXp6er3j6enpOnr0qEeKgrm40tNKbywAAGgut8fY9unTR3/961/rHc/NzVViYqJHigIAAADc5XaP7cMPP6ypU6dq8+bNzjG2W7duVV5eXoOBF3CFy0uCAQAAXIDbwfaGG27Q9u3b9fTTT2vt2rWSpAEDBmjHjh0aNmyYp+tDgHBluS8AAIDGNGkd2xEjRujPf/6zp2tBAGPzBQAA0FxNWsfWnxw6dEjjxo1TUlKShgwZor/97W9Gl4QmqF3uSxKbLwAAgCZp1s5j/iAkJERLlizR0KFDdezYMY0YMUJXXXWV2rRpY3RpcAPLfQEAgOZq8cG2U6dO6tSpkyQpPj5eMTExOnXqFMG2hWG5LwAA0FyGD0XYvHmzpkyZooSEBFksFueEtB+y2Wzq0aOHWrVqpbS0NO3YsaPBe3388ceqqalR165dvVw1AAAA/I3hwbaiokLJycmy2WwNns/NzVV2drbmz5+v3bt3Kzk5WZMmTdLx48frXHfq1ClNmzZNy5cv90XZAAAA8DNuD0UYPnx4o+d3797t1v0mT56syZMnX/D84sWLdfvtt2v69OmSpGXLlumtt97SihUrNHfuXElSZWWlMjIyNHfu3AZ3RfuhyspKVVZWOl+XlZVJkqqrq1VdXe1W7e6qvb+3nxPoaGfvo419g3b2PtrYN2hn3zBzO7v6niwOh8Phzo2DgoL0m9/8Rm3btpXD4dCiRYs0c+ZMRUVFSZLmz5/vfrW1xVgsWrNmjTIyMiRJVVVVioiI0OrVq53HJCkzM1OlpaVat26dHA6Hbr75ZvXr108LFiy46DMWLFighx9+uN7xVatWKSIiosm1AwAAwDvOnj2rm2++WadPn1a7du0ueF2Tgu2xY8cUGxsrSYqMjNTevXvVq1ev5lWs+sH2yJEj6ty5s7Zt26ZRo0Y5r7vvvvv0/vvva/v27dqyZYsuu+wyDRkyxHn+lVde0eDBgxt8RkM9tl27dtWJEycabShPqK6u1oYNGzRx4kSFhoZ69VmBjHb2PtrYN2hn76ONfYN29g0zt3NZWZliYmIuGmzdHorQpk0bnTlzRrGxsTp37py+//573XfffcrJyVHbtm2bVXRTjBkzRna73eXrw8PDFR4eXu94aGioz/4Q+PJZgYx29j7a2DdoZ++jjX2DdvYNM7azq+/H7cljgwcP1oMPPqiPPvpI9913n+Lj4xUcHKyUlBTl5+e7XWhjYmJiFBwcrOLi4jrHi4uLFR8f79FnAQAAoGVzO9g+9dRT+uCDD5Senq6XX35Zy5YtU25urn71q19p9OjRHi0uLCxMI0aMUF5envOY3W5XXl5enaEJTWGz2ZSUlKSRI0c2t0wAAAD4AbeHIowaNUrffvutSkpKFBUVpeDgYElSdna2UlNT3S7gzJkzKiwsdL4uKirSnj17FBUVpW7duik7O1uZmZlKSUlRamqqlixZooqKCucqCU1ltVpltVpVVlam9u3bN+teAAAAMF6Tdx675JJL6h0bM2aM2/fZtWuXxo8f73ydnZ0t6fzKBzk5OZo6dapKSko0b948HTt2TEOHDtX69esVFxfX1NIBAABgQk0Otvn5+frmm29UVVVV5/g111zj1n3GjRuniy3MkJWVpaysLLdrBAAAQOBwO9h++eWXuu666/TZZ5/JYrE4Q6nFYpEk1dTUeLZCL7HZbLLZbC2mXgAAADTO7cljs2fPVs+ePXX8+HFFREToX//6lzZv3qyUlBRt2rTJCyV6h9VqVX5+vnbu3Gl0KQAAAPAAt3tsP/zwQ23cuFExMTEKCgpSUFCQxowZo0WLFmnWrFn65JNPvFEnAAAADOZwOLTt4EkVFJcrMS5S6b2jnZ/a+wO3g21NTY0iIyMlnV9n9siRI+rXr5+6d++uAwcOeLxAAAAA+IdtB09q2oodqrE7FBxk0crpqRqdGGN0WU5uB9tBgwZp79696tmzp9LS0vTEE08oLCxMy5cv98i2ugAAAPA9u92uNz49qgPHytUvPlJThnRSUFDdUasFxeWqsZ+fX1Vjd6igpLxlB9uHHnpIFRUVkqSFCxfqpz/9qcaOHavo6Gjl5uZ6vEBvYfIYAAAwmj99tP/Gp0eV/de9zt5YOaRrh3Wuc01iXKSCgyzOaxJjIw2p9ULcDraTJk1yft+nTx/t379fp06dUseOHf1qjMXFsEEDAAAwmj99tH/gWN3e2C+Ol9e7Jr13tFZOT1VBSbkSY88HcX/S5HVsfygqKsoTtwEAAAgo/vTRfr/4ur2xfePq98ZaLBaNTozxq+EHP+R2sL3++usbPf/3v/+9ycUAAAAEEn/6aH/KkE6SQ/rieLn6xp0fY9vSuB1sf/ix/apVqzRlyhTnKgkAAABwnT99tB8UFFRvTG1L43awffnll53fr169Wk888QSrIQAAADSBv3+039J4ZIxtS8SqCACAlsafZtAD/ihggy2rIgAAWpqPvjyptz47qorKc/ri+BkFSRrVh54+oJbbwXbp0qXO78+dO6ecnBzFxPznL9WsWbM8UxnQwtGzAgQGX/5d/7LkjHJ3HnJONErqFEmwBX7A7WD79NNPO7+Pj4/XK6+84nxtsVgItggIrvxD5k9rEwLwHl/+XT9VUV1naajvKqq98hygpXI72BYVFXmjDqBFceUfMn9amxCA9/jy7/rw7h3qLA01vHsHrzwHaKk8Msa2pqZGwcHBnrgV0CK48g+ZP61NCMB7fPl3Pb13jN8sDQX4o2YF23379mnq1KnKz89X3759lZubq8GDB3uqNsBvufIPmT+tTQjAe3z5d52loYDGNSvY3nvvverUqZMef/xxvfLKK5o9e7Y2btzoqdq8iuW+0Byu/EPGP0BAYODvOuA/mhVsd+/erTfffFPDhw/X8OHD1b9/f0/V5XUs94Xm4B8ywDtYTQRAczQr2JaXl6tDhw6SpI4dO6q8vNwTNQEAAhSriQBoDreD7euvv+783m63Ky8vT59//rmqq1lyBADQPKwmAqA53A62GRkZdV7/+te/dn7Px0UAgOZgNREAzeF2sLXb7d6oAzAdxgoC7mM1EQDN4ZF1bAHUx1hBwH1MzATQHG4H2+zs7EbPL168uMnFAGbCWEF4G58KAEBdbgfbJUuWaNSoUQoLC6t3riX9B5V1bOFtjBWEt/GpAADU1aShCGvWrFFsbKyna/Ep1rGFtzFWEN7GpwIAUJfbwdZisbSonlnAKL4cK8hH0ubjcDj00ZcnJUkffXlSY/rG1fud8qkAANTldrB1OBy69dZb1bZtW7Vp00YJCQkaNmyYJk+erIiICG/UCOAi+EjafLYdPKlf//ljLUqRfv3nj/XitLR6v1M+FQCAuoLc/YFp06bpkksuUUhIiEpKSvT222/rv//7v5WYmKh9+/Z5o0YAF9HQR9Jo2Vz5ndZ+KnBrek+N7hNDLz2AgOd2j21OTk69YxUVFbrpppt077336s033/REXQDcwEfSjWuJQzVqf6eS+J0CgIs8so5tmzZt9Pvf/14LFizwxO0AuGlUrygtvjFZXxwvV9+4SI3qFWV0SX6lJQ7VSO8drT/cMkKnDmzXH34xgmEGAOCCZgXb77//Xq1atZIk9evXT3/5y188UhQQKDzVk/jhl6eU/be9zuAW0ybc74ObL/nb6gGu/N4tFosu7R2tfxyQLu3V8J+LltgTDQDe1KQtdR999FEtW7ZMxcXF+uKLL9SrVy/99re/VY8ePfTLX/7SG3UCpuSpnkR/C27+xt+Ganjq994Se6IBwJvcnjz2yCOPKCcnR0888USdTRoGDRqkl156yaPFAWbnqUlfjMdsXO3qAQuuSdLKGamGf6zvqd87kwYBoC63e2xXrlyp5cuXa8KECZo5c6bzeHJysvbv3+/R4gCz81RPIss+Nc6Xawq7IjGu7Y9+722beB//6okGAKO5HWwPHz6sPn361Dtut9tVXV3tkaJ8gS114Q88FUj9LbihcUEWi6amdFFFVY3ahIcoSE0bF+upPz+M1QVgFm4H26SkJH3wwQfq3r17neOrV6/WsGHDPFaYt7GlLvyGRZLD6CLgSweOlWvVjkPO133j2mpUH/f/p8RT/0PDWF0AZuF2sJ03b54yMzN1+PBh2e12/f3vf9eBAwe0cuVK1rAF3ESgCEyeGorgKUw+BGAWbgfba6+9Vm+88YYWLlyoNm3aaN68eRo+fLjeeOMNTZw40Rs1AqZVVFKuqSldVVF1Tm3CQlR0kkARCDw1FMFTGKsLwCyatI7t2LFjtWHDBk/XAgScyNZhyt11yBkoFt+Y7LVnMY7Sf3hqKIKnMPkQgFm4HWx79eqlnTt3Kjqa//ABzXWqoqrOR8Dfna3y2rMY9uA//K2HlMmHAMzC7WD71VdfsZIA4CF9fxxw4rwXcBhH6T/oIYVZ8EkQ/E2ThiLwhxbwDF8GHH/rJQxk9JDCLPgkCP6mScE2JSVFwcHBDZ778ssvm1UQEEg8FXBc6TWhlxCAp/FJEPxNk4Ltb37zG9Z+BfyIK70m9BIC8DQ+CYK/cTvYWiwW/b//9/8UGxvrjXoANAG9JgCMwCdB8DduB1uHgy2SAH9Dr0nzMQkGcB+fBMHfuB1sX375ZYYhAH6GXpPmYxJM4wj+AFoCt4NtZmamN+oA0Az0mjQfwzkaR/AH0BK4HWyjoqIaPX/q1KkmFwMARmE4R+MI/gBagiaNsbXb7br77rvVs2dPb9TkEzabTTabjc0m4DV8dNuyMJyjcQR/AC2B28H24MGDWrBggZ566inNnDlTDz30UIscc2u1WmW1WlVWVtYi64f/46PbloXhHI0j+ANoCYLc/YGoqCgtXbpUH3/8sQoLC9WnTx89++yz9HwCP9LQR7dAS1Ub/G9N76nRfWL49AGAX3I72Nbq27ev1qxZo//93//VypUrlZSUpLVr13qwNKBlq/3oVpJffHTrcDi0tfCEcrYWaWvhiQaX7nPlGl/WAwCAO9weinD99dfXO9a5c2ft379fN9xwAz23wP/xt49uXRka4cvhEwzVAAB4mtvB9kLjUX/2s581uxjATPxtzKYrs9p9OfOdWfYAAE9r0gYNAFoeV2a1+3LmO7PsAQCe5nawLSoq0rlz55SYmFjneEFBgUJDQ9WjRw9P1QbAg1wZGuHL4ROuPMuXS6axPBsAtHxuB9tbb71VM2bMqBdst2/frpdeekmbNm3yVG0AXORyKLNIamSOli+HT7jyLMb8AgDc4Xaw/eSTTzR69Oh6xy+99FJlZWV5pCgA7vG3iWGewphfAIA73A62FotF5eX11+M8ffo0KyIABvG3iWGe0i8+UjendVNF5Tm1CQ9RvzjG/AIALsztYHvZZZdp0aJF+stf/qLg4GBJUk1NjRYtWqQxY8Z4vEAAF+dvE8M8pcbuUO7OQ86arxoU77Vn+dvybAAA97kdbP/nf/5Hl112mfr166exY8dKkj744AOVlZVp48aNHi8QwMX528QwT/nkm9I6vcyffFOqMYmXeOVZ/rY8GwDAfW4H26SkJH366ad67rnntHfvXrVu3VrTpk1TVlaWoqKivFEjgItwJZS1xOAW1Sa0Ti9zVNtQo0sCAPgxt4OtJCUkJOixxx7zdC0AUEevS9pqakoXVVTVqE14iHrFtDW6JACAH2tSsC0tLdUf//hH7du3T5I0cOBAzZgx44K7kgEILHa7XW98elQHjpWrX3ykpgzppKCgILfvc2mvaNntcg6fuLSX/w+fAAAYx+1gu2vXLk2aNEmtW7dWamqqJGnx4sV69NFH9e6772r48OEeLxJAy/LGp0eV/de9ziEEckjXDuvctJtdZO1dAABquR1s7777bl1zzTV68cUXFRJy/sfPnTun2267TXPmzNHmzZs9XiQA3/DU7lsHjtVdWuyL4/WXCHTFR1+e1FufHVVF5Tl9cfyMgiSN6tNyxggDAHyrST22Pwy1khQSEqL77rtPKSkpHi0OgG95ahOHfvF1lxbr28T1Z78sOVNnua+kTpEEWwDABbkdbNu1a6dvvvlG/fv3r3P80KFDioz0/3UxAVzYFz/exOF40zZxmDKkk+SQvjherr5x58fY/pgrvcOnKqrr1PNdRXUT3hUAIFC4HWynTp2qX/7yl3ryySeVnp4uSdq6davuvfde3XTTTR4v0BXXXXedNm3apAkTJmj16tWG1ACYQVSbsDo9rR0jwpp0n6CgoIuOqXWld3h49w516hnevUOT6gEABAa3g+2TTz4pi8WiadOm6dy5c5Kk0NBQ3XHHHXr88cc9XqArZs+erRkzZuhPf/qTIc8HzKL831X6eUoXna2qUZuwEJVXVnntWa5s8ZveO6bFbSoBADCO28E2LCxMzzzzjBYtWqSDBw9Kknr37q2IiAiPF+eqcePGadOmTYY9HzCLnpdEav4b+/7Tizoj1WvPcmWL35a4qQQAwDjuLyz5fyIiIjR48GANHjy4WaF28+bNmjJlihISEmSxWLR27dp619hsNvXo0UOtWrVSWlqaduzY0eTnAbiw2m13F1yTpJUzUr3aQ+rLZwEAAoPbPbbXX399o+f//ve/u3W/iooKJScna8aMGQ3eOzc3V9nZ2Vq2bJnS0tK0ZMkSTZo0SQcOHFBsbKxbzwLQOF/2kNIbCwDwNLeD7Q93F1u1apWmTJnSrNUQJk+erMmTJ1/w/OLFi3X77bdr+vTpkqRly5bprbfe0ooVKzR37ly3n1dZWanKykrn67KyMklSdXW1qqu9O+O69v7efk6go529jzb2DdrZ+2hj36CdfcPM7ezqe7I4HI4m7+kTGRmpvXv3qlevXk29Rd1iLBatWbNGGRkZkqSqqipFRERo9erVzmOSlJmZqdLSUq1bt855bNOmTXruuecuuirCggUL9PDDD9c7vmrVKkPHCQMAAKBhZ8+e1c0336zTp0+rXbt2F7zO7R5bXzpx4oRqamoUFxdX53hcXJz279/vfH355Zdr7969qqioUJcuXfS3v/1No0aNavCeDzzwgLKzs52vy8rK1LVrV11xxRWNNpQnVFdXa8OGDZo4caJCQ0O9+qxARjt7H23sG7Sz99HGvkE7+4aZ27n2E/aL8etg66p//vOfLl8bHh6u8PDwesdDQ0N99ofAl88KZLSz99HGvkE7ex9t7Bu0s2+YsZ1dfT9uB9ulS5c6vz937pxycnIUE/OfyR+zZs1y95YXFBMTo+DgYBUXF9c5XlxcrPj4eI89BwAAAC2f28H26aefdn4fHx+vV155xfnaYrF4NNiGhYVpxIgRysvLc46xtdvtysvLU1ZWVrPubbPZZLPZVFNT44FKAQAAYDS3g21RUZFHCzhz5owKCwvr3H/Pnj2KiopSt27dlJ2drczMTKWkpCg1NVVLlixRRUWFc5WEprJarbJarSorK6uz0gMAAABaJreD7cKFC3XPPfd4bAWBXbt2afz48c7XtRO7MjMzlZOTo6lTp6qkpETz5s3TsWPHNHToUK1fv77ehDIAAAAENreD7cMPP6yZM2d6LNiOGzdOF1txLCsrq9lDDwAAAGBubm+p24xlbwEAAACvadJyX08++aTatm3b4Ll58+Y1qyBfYfIYAACAuTQp2G7dulVhYWH1jlsslhYTbJk8BgAAYC5NCrZr1qxRbGysp2sBAAAAmswUO48BuDiHw6FtB0+qoLhciXGRSu8dLYvFYnRZAAB4jNvB9ic/+UmDwxAA+LdtB09q2oodqrE7FBxk0crpqRqdGHPxHwQAoIVwe1WE9957Tx06dNCJEyd04sQJb9TkEzabTUlJSRo5cqTRpQA+UVBcrhr7+VVNauwOFZSUG1wRAACe5VawLS0tldVqVUxMjOLi4hQXF6eYmBhlZWWptLTUSyV6h9VqVX5+vnbu3Gl0KYBPJMZFKjjo/NCD4CCLEmMjDa4IAADPcnkowqlTpzRq1CgdPnxYt9xyiwYMGCBJys/PV05OjvLy8rRt2zZ17NjRa8UCaLr03tFaOT1VBSXlSow9P8YWnsdYZgAwjsvBduHChQoLC9PBgwfrbWe7cOFCXXHFFVq4cKGefvppjxcJoPksFotGJ8YwrtbLGMsMAMZxeSjC2rVr9eSTT9YLtZIUHx+vJ554QmvWrPFocQBaJofDoa2FJ5SztUhbC08E1I6FjGUGAOO43GN79OhRDRw48ILnBw0apGPHjnmkKF9g5zHAewK517J2LHPte2csMwD4jsvBNiYmRl999ZW6dOnS4PmioiJFRUV5rDBvY+cxwHsa6rUMlGDLWGYAMI7LQxEmTZqkBx98UFVVVfXOVVZW6re//a2uvPJKjxYHoGUK5BUYascy35reU6P7xDBxDAB8yK3JYykpKUpMTJTValX//v3lcDi0b98+Pf/886qsrNQrr7zizVoBtBD0WgIAjOBysO3SpYs+/PBD3XnnnXrggQeck0EsFosmTpyo5557Tl27dvVaoQBaGIukZs4ZY+ksAIA73NpSt2fPnnr77bf13XffqaCgQJLUp0+fFjW2FoD3eWryWCBPQgMAuM/tLXUlqWPHjkpNTVVqaiqhFkA9nlryiqWzAADuaFKwNQObzaakpCSNHDnS6FIA0/HU5LFAnoQGAHCfW0MRzITlvgDv8dTkMSahAQDcEbDBFoD3uLJ9rysTw9gGGADgDoItAEMwMQwA4GkBO8YWgPc4HA5tLTyhnK1F2lp4wrk84A8xMQwA4Gn02ALwOFd6Y2snhtVew8QwAEBzEWwBeFxDvbE/DrZMDAMAeBrBFoDHudIby8QwAICnEWwBeBy9sQAAIwRssLXZbLLZbKqpqTG6FMB06I0FABghYFdFsFqtys/P186dO40uBQAAAB4QsD22QKBxZUMEAABaMoItECDYEAEAYHYBOxQBCDRsiAAAMDuCLRAgapfgksSGCAAAU2IoAhAgWIILAGB2BFsgQLAEFwDA7BiKAAAAAFMg2AIAAMAUCLYAAAAwhYANtjabTUlJSRo5cqTRpQAAAMADAjbYsqUu4D0Oh0NbC08oZ2uRthaekMPhMLokAEAAYFUEAB7HLmcAACMEbI8tAO9hlzMAgBEItgA8jl3OAABGYCgCAI9jlzMAgBEItgA8jl3OAABGYCgCAAAATIFgCwAAAFMg2AIAAMAUCLYAAAAwBYItAAAATIFgCwAAAFMg2AIAAMAUCLYAAAAwhYANtjabTUlJSRo5cqTRpQAAAMADAjbYWq1W5efna+fOnUaXAgAAAA8I2GALAAAAcyHYAgAAwBQItgAAADAFgi0AAABMgWALAAAAUyDYAgAAwBQItgAAADAFgi0AAABMgWALAAAAUyDYAgAAwBQItgAAADAFgi0AAABMgWALAAAAUyDYAgAAwBQItgAAADAFgi0AAABMgWALAAAAUyDYAgAAwBRMEWzffPNN9evXT4mJiXrppZeMLgcAAAAGCDG6gOY6d+6csrOz9d5776l9+/YaMWKErrvuOkVHRxtdGgAAAHyoxffY7tixQwMHDlTnzp3Vtm1bTZ48We+++67RZQEAAMDHDA+2mzdv1pQpU5SQkCCLxaK1a9fWu8Zms6lHjx5q1aqV0tLStGPHDue5I0eOqHPnzs7XnTt31uHDh31ROgAAAPyI4cG2oqJCycnJstlsDZ7Pzc1Vdna25s+fr927dys5OVmTJk3S8ePHfVwpAAAA/JnhY2wnT56syZMnX/D84sWLdfvtt2v69OmSpGXLlumtt97SihUrNHfuXCUkJNTpoT18+LBSU1MveL/KykpVVlY6X5eVlUmSqqurVV1d3dy306ja+3v7OYGOdvY+2tg3aGfvo419g3b2DTO3s6vvyeJwOBxersVlFotFa9asUUZGhiSpqqpKERERWr16tfOYJGVmZqq0tFTr1q3TuXPnNGDAAG3atMk5eWzbtm0XnDy2YMECPfzww/WOr1q1ShEREd54WwAAAGiGs2fP6uabb9bp06fVrl27C15neI9tY06cOKGamhrFxcXVOR4XF6f9+/dLkkJCQvTUU09p/Pjxstvtuu+++xpdEeGBBx5Qdna283VZWZm6du2qK664otGG8oTq6mpt2LBBEydOVGhoqFefFchoZ++jjX2DdvY+2tg3aGffMHM7137CfjF+HWxddc011+iaa65x6drw8HCFh4fXOx4aGuqzPwS+fFYgo529jzb2DdrZ+2hj36CdfcOM7ezq+zF88lhjYmJiFBwcrOLi4jrHi4uLFR8fb1BVAAAA8Ed+HWzDwsI0YsQI5eXlOY/Z7Xbl5eVp1KhRzbq3zWZTUlKSRo4c2dwyAQAA4AcMH4pw5swZFRYWOl8XFRVpz549ioqKUrdu3ZSdna3MzEylpKQoNTVVS5YsUUVFhXOVhKayWq2yWq0qKytT+/btm/s2AAAAYDDDg+2uXbs0fvx45+vaiV2ZmZnKycnR1KlTVVJSonnz5unYsWMaOnSo1q9fX29CGQAAAAKb4cF23LhxutiKY1lZWcrKyvJRRQAAAGiJ/HqMrTcxxhYAAMBcAjbYWq1W5efna+fOnUaXAgAAAA8I2GALAAAAcyHYAgAAwBQItgAAADCFgA22TB4DAAAwl4ANtkweAwAAMJeADbYAAAAwF4ItAAAATIFgCwAAAFMg2AIAAMAUAjbYsioCAACAuQRssGVVBAAAAHMJ2GALAAAAcyHYAgAAwBQItgAAADAFgi0AAABMgWALAAAAUwjYYMtyXwAAAOYSsMGW5b4AAADMJWCDLQAAAMyFYAsAAABTINgCAADAFAi2AAAAMAWCLQAAAEyBYAsAAABTCNhgyzq2AAAA5hKwwZZ1bAEAAMwlYIMtAAAAzIVgCwAAAFMg2AIAAMAUQowuAEBgcjgc2nbwpAqKy5UYF6n03tGyWCxGlwUAaMEItgAMse3gSU1bsUM1doeCgyxaOT1VoxNjjC4LANCCMRQBgCEKistVY3dIkmrsDhWUlBtcEQCgpSPYAjBEYlykgoPODz0IDrIoMTbS4IoAAC0dQxEAGCK9d7RWTk9VQUm5EmPPj7EFAKA5CLYADGGxWDQ6MYZxtQAAjwnYoQhsqQsAAGAuARts2VIXAADAXBiKAMDjWKMWAGAEgi0Aj2ONWgCAEQJ2KAIA72GNWgCAEQi2ADyONWoBAEZgKAIAj2ONWgCAEQi2ADyONWoBAEZgKAIAAABMgWALAAAAUyDYAgAAwBQItgAAADAFgi0AAABMgWALAAAAUyDYAgAAwBQCNtjabDYlJSVp5MiRRpcCAAAADwjYYGu1WpWfn6+dO3caXQoAAAA8IGCDLQAAAMyFYAsAAABTINgCAADAFAi2AAAAMAWCLQAAAEyBYAsAAABTINgCAADAFEKMLsBoDodDklRWVub1Z1VXV+vs2bMqKytTaGio158XqGhn76ONfYN29j7a2DdoZ98wczvX5rTa3HYhAR9sy8vLJUldu3Y1uBIAAAA0pry8XO3bt7/geYvjYtHX5Ox2u44cOaLIyEhZLBavPqusrExdu3bVoUOH1K5dO68+K5DRzt5HG/sG7ex9tLFv0M6+YeZ2djgcKi8vV0JCgoKCLjySNuB7bIOCgtSlSxefPrNdu3am+wPnj2hn76ONfYN29j7a2DdoZ98wazs31lNbi8ljAAAAMAWCLQAAAEyBYOtD4eHhmj9/vsLDw40uxdRoZ++jjX2DdvY+2tg3aGffoJ2ZPAYAAACToMcWAAAApkCwBQAAgCkQbAEAAGAKBFsAAACYAsHWR2w2m3r06KFWrVopLS1NO3bsMLok09m8ebOmTJmihIQEWSwWrV271uiSTGfRokUaOXKkIiMjFRsbq4yMDB04cMDoskzlhRde0JAhQ5wLrI8aNUpvv/220WWZ3uOPPy6LxaI5c+YYXYqpLFiwQBaLpc5X//79jS7LdA4fPqxf/OIXio6OVuvWrTV48GDt2rXL6LIMQbD1gdzcXGVnZ2v+/PnavXu3kpOTNWnSJB0/ftzo0kyloqJCycnJstlsRpdiWu+//76sVqs++ugjbdiwQdXV1briiitUUVFhdGmm0aVLFz3++OP6+OOPtWvXLv3Xf/2Xrr32Wv3rX/8yujTT2rlzp/7whz9oyJAhRpdiSgMHDtTRo0edX1u2bDG6JFP57rvvNHr0aIWGhurtt99Wfn6+nnrqKXXs2NHo0gzBcl8+kJaWppEjR+q5556TJNntdnXt2lV33XWX5s6da3B15mSxWLRmzRplZGQYXYqplZSUKDY2Vu+//74uu+wyo8sxraioKP3+97/XL3/5S6NLMZ0zZ85o+PDhev755/XII49o6NChWrJkidFlmcaCBQu0du1a7dmzx+hSTGvu3LnaunWrPvjgA6NL8Qv02HpZVVWVPv74Y11++eXOY0FBQbr88sv14YcfGlgZ0HynT5+WdD54wfNqamr02muvqaKiQqNGjTK6HFOyWq26+uqr6/w3Gp5VUFCghIQE9erVS7fccou++eYbo0sylddff10pKSm68cYbFRsbq2HDhunFF180uizDEGy97MSJE6qpqVFcXFyd43FxcTp27JhBVQHNZ7fbNWfOHI0ePVqDBg0yuhxT+eyzz9S2bVuFh4dr5syZWrNmjZKSkowuy3Ree+017d69W4sWLTK6FNNKS0tTTk6O1q9frxdeeEFFRUUaO3asysvLjS7NNL788ku98MILSkxM1DvvvKM77rhDs2bN0p/+9CejSzNEiNEFAGiZrFarPv/8c8bLeUG/fv20Z88enT59WqtXr1ZmZqbef/99wq0HHTp0SLNnz9aGDRvUqlUro8sxrcmTJzu/HzJkiNLS0tS9e3f99a9/ZWiNh9jtdqWkpOixxx6TJA0bNkyff/65li1bpszMTIOr8z16bL0sJiZGwcHBKi4urnO8uLhY8fHxBlUFNE9WVpbefPNNvffee+rSpYvR5ZhOWFiY+vTpoxEjRmjRokVKTk7WM888Y3RZpvLxxx/r+PHjGj58uEJCQhQSEqL3339fS5cuVUhIiGpqaowu0ZQ6dOigvn37qrCw0OhSTKNTp071/qd3wIABATvkg2DrZWFhYRoxYoTy8vKcx+x2u/Ly8hgzhxbH4XAoKytLa9as0caNG9WzZ0+jSwoIdrtdlZWVRpdhKhMmTNBnn32mPXv2OL9SUlJ0yy23aM+ePQoODja6RFM6c+aMDh48qE6dOhldimmMHj263rKLX3zxhbp3725QRcZiKIIPZGdnKzMzUykpKUpNTdWSJUtUUVGh6dOnG12aqZw5c6ZOL0BRUZH27NmjqKgodevWzcDKzMNqtWrVqlVat26dIiMjnePE27dvr9atWxtcnTk88MADmjx5srp166by8nKtWrVKmzZt0jvvvGN0aaYSGRlZb2x4mzZtFB0dzZhxD7rnnns0ZcoUde/eXUeOHNH8+fMVHBysm266yejSTOPuu+9Wenq6HnvsMf385z/Xjh07tHz5ci1fvtzo0ozhgE88++yzjm7dujnCwsIcqampjo8++sjokkznvffec0iq95WZmWl0aabRUPtKcrz88stGl2YaM2bMcHTv3t0RFhbmuOSSSxwTJkxwvPvuu0aXFRB+8pOfOGbPnm10GaYydepUR6dOnRxhYWGOzp07O6ZOneooLCw0uizTeeONNxyDBg1yhIeHO/r37+9Yvny50SUZhnVsAQAAYAqMsQUAAIApEGwBAABgCgRbAAAAmALBFgAAAKZAsAUAAIApEGwBAABgCgRbAPCC6upqo0sAgIBDsAUAD9izZ48yMzPVt29fdezYUe3atdPp06fdvs8333yjtm3b6rPPPtNjjz2m9PR0L1QLAOZEsAWACzh06JBmzJihhIQEhYWFqXv37po9e7ZOnjxZ57pNmzZpzJgxio+P12uvvaadO3eqsLBQ7du3d/uZCQkJ2rNnj/r166eZM2cqNzfXU28HAEyPnccAoAFffvmlRo0apb59++qRRx5Rz5499a9//Uv33nuvqqqq9NFHHykqKkoOh0N9+/bV/fffr9tuu83osgEgoNFjCwANsFqtCgsL07vvvquf/OQn6tatmyZPnqx//vOfOnz4sB588EFJ0v79+/X111+rsLBQ3bt3V6tWrXTppZdqy5YtkqQTJ07IYrE4vzIyMhp97pYtWzR27Fi1bt1aXbt21axZs1RRUeE836NHD1ksFu3evdt5rLq6WnFxcbJYLPrqq68ueO8f1vHDrzlz5tS5bsGCBfWu+WHd3333naZNm6aOHTsqIiJCkydPVkFBQb3n1db6w6+1a9c6z69fv15jxoxRhw4dFB0drZ/+9Kc6ePBgo+0DAI0h2ALAj5w6dUrvvPOO7rzzTrVu3brOufj4eN1yyy3Kzc2Vw+FQSUmJqqur9corr+iFF17QJ598oqFDh+rKK6/U0aNHFR0draNHj+ro0aP6+c9/3uhzDx48qCuvvFI33HCDPv30U+Xm5mrLli3Kysqqc13nzp21fPly5+s1a9YoNDTUpff28ssvO+s5evSoRo0aVe8ah8OhgQMHXrDuW2+9Vbt27dLrr7+uDz/8UA6HQ1dddVWDE+YWLlzovM+PVVRUKDs7W7t27VJeXp6CgoJ03XXXyW63u/ReAODHCLYA8CMFBQVyOBwaMGBAg+cHDBig7777TiUlJc4Q9vvf/15XXXWVBgwYoOeff14JCQmy2WyyWCyKj49XfHx8vZD8Y4sWLdItt9yiOXPmKDExUenp6Vq6dKlWrlyp77//3nndf//3f2v16tXOntzly5drxowZLr23Dh06OOuJj49XWFhYvWuqq6vVunXrBusuKCjQ66+/rpdeekljx45VcnKyXn31VR0+fLhOb6wkVVZWKioqynmfH7vhhht0/fXXq0+fPho6dKhWrFihzz77TPn5+S69FwD4MYItAFyAO1MQRo8e7fw+KChI6enpDQa0N998U23btlWHDh00ePBg2Ww257m9e/cqJydHbdu2dX5NmjRJdrtdRUVFzuvi4uI0btw4vfbaazp48KDy8/M1ZcqUJr7L+srKytSmTZsGz+3bt08hISFKS0tzHouOjla/fv20b9++OteeOnVK7dq1u+BzCgoKdNNNN6lXr15q166devToIen8yhAA0BQhRhcAAP6mT58+slgs2rdvn6677rp65/ft26eOHTvqkksuUceOHS94H4vFUu/Y+PHj9cILL+jcuXPatGmTrFar+vfvrwkTJujMmTP69a9/rVmzZtX7uW7dutV5/atf/Urz5s3TF198oczMTJeHIrjiyJEjSkhIaNY9vv32W1VVValnz54XvGbKlCnq3r27XnzxRSUkJMhut2vQoEGqqqpq1rMBBC56bAHgR6KjozVx4kQ9//zz+ve//13n3LFjx/Tqq69q6tSpslgs6t27t0JCQrR161bnNXa7Xdu2bVNSUlK9e7dp00Z9+vRR//79NXPmTPXs2VOffPKJJGn48OHKz89Xnz596n39eMjAxIkTVVJSomXLlnl0NQa73a7du3dr2LBhDZ4fMGCAzp07p+3btzuPnTx5UgcOHKjzft9//321bt1aKSkpDd6n9mceeughTZgwwTm8AwCag2ALAA147rnnVFlZqUmTJmnz5s06dOiQ1q9fr4kTJ6pz58569NFHJUlt27bV7bffrnvvvVf/+Mc/tG/fPt155506cuSI7rzzznr3rays1LFjx/Ttt99q1apV+uqrrzR48GBJ0v33369t27YpKytLe/bsUUFBgdatW1dv8ph0vjd42bJlevLJJ9W7d2+PvOdDhw7p9ttv1/HjxzV16tQGr0lMTNS1116r22+/XVu2bNHevXv1i1/8Qp07d9a1114r6fwkuMcff1zXXnutSktLdezYMR07dkySVFpaqqqqKnXs2FHR0dFavny5CgsLtXHjRmVnZ3vkfQAIXAxFAIAGJCYmateuXZo/f75+/vOf69SpU4qPj1dGRobmz5+vqKgo57VPPvmkLBaLMjMzVVZWpuHDh+udd95Rp06d6t13/fr16tSpk0JCQtStWzc9/vjjmjRpkiRpyJAhev/99/Xggw9q7Nixcjgc6t279wVD5sSJEz36np955hkVFhbq3XffrTf04YdefvllzZ49Wz/96U9VVVWlyy67TP/4xz+cwyEmTJigr7/+Wp9//rlee+21Oj87ffp09ejRwzlGeNasWRo0aJD69eunpUuXaty4cR59TwACCxs0AAA8qkePHtq0aZNzMtgPZWRkaM6cOQRYAF7BUAQAgEddcsklCg4ObvBcx44dG1xiDAA8gR5bAAAAmAI9tgAAADAFgi0AAABMgWALAAAAUyDYAgAAwBQItgAAADAFgi0AAABMgWALAAAAUyDYAgAAwBQItgAAADAFgi0AAABM4f8DzslOFcuRBgYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.scatterplot(\n",
    "    data=test,\n",
    "    x='RootVolume',\n",
    "    y='MAPE',\n",
    "    # hue='color',\n",
    "    # palette={'Доп разметка': 'red', 'Без': 'blue'},\n",
    "    s=10, \n",
    "    # legend='full'\n",
    ")\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel(\"Относительная ошибка, %\")\n",
    "ax.set_xlabel(\"Объём плода\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006e0cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.706\n"
     ]
    }
   ],
   "source": [
    "print(np.round(np.quantile(test[\"MAPE\"], q=0.5), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
