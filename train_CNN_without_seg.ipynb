{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b12b90b4",
   "metadata": {},
   "source": [
    "# Обучение CNN модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc67dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aec16f8",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05636a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"images/train\"\n",
    "test_data_path = \"images/test\"\n",
    "\n",
    "train_df = pd.read_csv(\"data/Train.csv\")\n",
    "test_df = pd.read_csv(\"data/Test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a91bc65",
   "metadata": {},
   "source": [
    "### Извлечение сегментов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed50c9b0",
   "metadata": {},
   "source": [
    "Теперь нужно подготовить датасет для обучения модели-регрессора. Сперва извлечём сегменты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a62bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"early\" : YOLO(\"seg_models/best_early.pt\"),\n",
    "          \"late\" : YOLO(\"seg_models/best_late.pt\"),\n",
    "          \"full\" : YOLO(\"seg_models/best_full.pt\"),\n",
    "          \"best\" : YOLO(\"seg_models/best.pt\")}\n",
    "\n",
    "def get_segmented_images(models, image_paths, display_image=False, do_segment = True):\n",
    "    \"\"\"Извлечение детектированных сегментов\"\"\"\n",
    "    \n",
    "    if not do_segment:\n",
    "        return [Image.open(img) for img in image_paths], False\n",
    "    \n",
    "    best_res = None\n",
    "    for model in models.keys():\n",
    "        model = models[model]\n",
    "        results = model(image_paths, verbose=False)\n",
    "        if best_res is None or len(results[0].boxes.xyxy) >= len(best_res[0].boxes.xyxy):\n",
    "            best_res = results\n",
    "        # if len(results[0].boxes.xyxy) != 0:\n",
    "        #     break\n",
    "\n",
    "    results = best_res\n",
    "\n",
    "    was_segmented = len(results[0].boxes) > 3\n",
    "\n",
    "    if len(results[0].boxes.xyxy) == 0:\n",
    "        # в случае отсутствия детекций\n",
    "        return [Image.open(img) for img in image_paths], was_segmented\n",
    "        \n",
    "    segmented_images = []\n",
    "    \n",
    "    for img_path, result in zip(image_paths, results):\n",
    "        original_image = Image.open(img_path)\n",
    "        \n",
    "        # Пропускаем изображения без детекций\n",
    "        if len(result.boxes.xyxy) == 0:\n",
    "            continue \n",
    "            \n",
    "        # Оставляем сегменты\n",
    "        for box in result.boxes.xyxy:\n",
    "            x1, y1, x2, y2 = map(int, box.tolist())\n",
    "            segment = original_image.crop((x1, y1, x2, y2))\n",
    "            segmented_images.append(segment)\n",
    "            \n",
    "\n",
    "    # Отрисовка для демонстрации\n",
    "    if display_image and segmented_images:\n",
    "        fig, axes = plt.subplots(1, len(segmented_images), figsize=(15, 10))\n",
    "        if len(segmented_images) == 1:\n",
    "            axes = [axes]\n",
    "        for ax, img in zip(axes, segmented_images):\n",
    "            ax.imshow(img)\n",
    "            ax.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    return segmented_images, was_segmented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17566c77",
   "metadata": {},
   "source": [
    "### Загрузка серии срезов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef79746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(img_root : str, folder : str, side : str, start : int, end : int) -> list[str]:\n",
    "    \"\"\"Получение списка последовательности изображений\n",
    "\n",
    "    Args:\n",
    "        img_root (str): корневая папка с изображениями\n",
    "        folder (str): папка корня\n",
    "        side (str): (L|R) сторона\n",
    "        start (int): начальный срез\n",
    "        end (int): конечный срез\n",
    "\n",
    "    Returns:\n",
    "        list[str]: список путей до изображений\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for i in range(start, end + 1):\n",
    "        path = os.path.join(\n",
    "            img_root,\n",
    "            folder,\n",
    "            f\"{folder}_{side}_{i:03d}.png\"\n",
    "        )\n",
    "        if os.path.exists(path):\n",
    "            images.append(path)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8915c7",
   "metadata": {},
   "source": [
    "### Компоновка сегментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_segmented_images(root: str, folder: str, side: str, start: int, end: int, do_segment = True) -> Image:\n",
    "    \"\"\"Компоновка сегментов по серии срезов\n",
    "\n",
    "    Args:\n",
    "        root (str): корневой путь\n",
    "        folder (str): папка корня\n",
    "        side (str): (L|R) сторона\n",
    "        start (int): начальный срез\n",
    "        end (int): конечный срез\n",
    "\n",
    "    Returns:\n",
    "        Image: Итоговое изображение PIL.Image\n",
    "    \"\"\"\n",
    "    images_in_range = get_images(root, folder, side, start, end)\n",
    "    segmented_images, was_segmented = get_segmented_images(models, images_in_range, do_segment=do_segment)\n",
    "\n",
    "    total_width = sum(img.width for img in segmented_images)\n",
    "    max_height = max(img.height for img in segmented_images)\n",
    "    res = Image.new(\"RGBA\", (total_width, max_height * len(segmented_images)), (0, 0, 0, 0))\n",
    "    sqr_width = int(np.ceil(np.sqrt(total_width * max_height)))\n",
    "    x_offset = 0\n",
    "    y_offset = 0\n",
    "    actual_width = 0\n",
    "    for segment in segmented_images:\n",
    "        if x_offset + segment.width > sqr_width:\n",
    "            actual_width = max(actual_width, x_offset)\n",
    "            x_offset = 0\n",
    "            y_offset += max_height\n",
    "        res.paste(segment, (x_offset, y_offset))\n",
    "        x_offset += segment.width\n",
    "    actual_width = max(actual_width, x_offset)\n",
    "    actual_height = y_offset + max_height\n",
    "    res = res.crop((0, 0, actual_width, actual_height))\n",
    "\n",
    "    return res, was_segmented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5f2fa9",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92003edf",
   "metadata": {},
   "source": [
    "Предварительно будем трансформировать данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f472071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad626c8",
   "metadata": {},
   "source": [
    "### Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c438be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RootVolumeDataset(Dataset):\n",
    "    def __init__(self, df : pd.DataFrame, transform = None, is_train = True):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.df['ImageSegments'].iloc[index]).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.is_train:\n",
    "            label = self.df['RootVolume'].iloc[index]\n",
    "\n",
    "            return image, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb32f5c",
   "metadata": {},
   "source": [
    "Воспроизводимость результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211131e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed) \n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    L.pytorch.seed_everything(seed, workers=True)\n",
    "    \n",
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd82610",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = v2.Compose([\n",
    "    v2.Resize(size=(128, 128), antialias=True),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),  \n",
    "    v2.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "test_transform = v2.Compose([\n",
    "    v2.Resize(size=(128, 128), antialias=True),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),  \n",
    "    v2.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33fdf3f",
   "metadata": {},
   "source": [
    "### Регрессор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43a6ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RootVolumeRegressor(L.LightningModule):\n",
    "    def __init__(self, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "\n",
    "        # Fully Connected Regression Head\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)  # Regression output\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        preds = self(images).squeeze()\n",
    "        loss = self.criterion(preds, targets)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        preds = self(images).squeeze()\n",
    "        loss = self.criterion(preds, targets)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc6de7b",
   "metadata": {},
   "source": [
    "### Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcf3c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_preds(model, dataloader, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    preds, targets = [], []\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images, labels = batch\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)  # Predict\n",
    "\n",
    "            preds.extend(outputs.cpu().numpy().flatten())\n",
    "            targets.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "    return np.array(preds), np.array(targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f986081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(preds, targets):\n",
    "    \"\"\"\n",
    "    Вычисление RMSE\n",
    "    \"\"\"\n",
    "    preds = np.array(preds) if not isinstance(preds, np.ndarray) else preds\n",
    "    targets = np.array(targets) if not isinstance(targets, np.ndarray) else targets\n",
    "    \n",
    "    return np.sqrt(np.mean((preds - targets) ** 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b6cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MAPE(preds, targets):\n",
    "    \"\"\"Вычисление MAPE\"\"\"\n",
    "    preds = np.array(preds) if not isinstance(preds, np.ndarray) else preds\n",
    "    targets = np.array(targets) if not isinstance(targets, np.ndarray) else targets\n",
    "    res = []\n",
    "    for i in range(len(targets)):\n",
    "        target = targets[i]\n",
    "        pred = preds[i]\n",
    "        if abs(target) < 1e-3:\n",
    "            continue\n",
    "        res.append((np.abs(pred - target) / target) * 100)\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bdc90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_preds(model, dataloader, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    preds = []\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images = batch if isinstance(batch, torch.Tensor) else batch[0]\n",
    "            images = images.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            preds.extend(outputs.cpu().numpy().flatten()) \n",
    "\n",
    "    return np.array(preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d705dac0",
   "metadata": {},
   "source": [
    "### Без сегментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d724bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regression_dataset(df : pd.DataFrame, output : str, src : str, type : str, do_segment : bool = False):\n",
    "    paths = []\n",
    "    was_segmented = []\n",
    "    widths = []\n",
    "    for _, row in tqdm(df.iterrows(), total = len(df), desc=\"Генерация датасета\"):\n",
    "        img, segm = merge_segmented_images(\n",
    "            root=src,\n",
    "            folder=row[\"FolderName\"],\n",
    "            side=row[\"Side\"],\n",
    "            start=row[\"Start\"],\n",
    "            end=row[\"End\"],\n",
    "            do_segment=do_segment\n",
    "        )\n",
    "        img_path = os.path.join(output, f'{row[\"ID\"]}.png')\n",
    "        img.save(img_path)\n",
    "        paths.append(img_path)\n",
    "        was_segmented.append(segm)\n",
    "        widths.append(img.width)\n",
    "    df[\"WasSegmented\"] = was_segmented\n",
    "    df[\"ImageSegments\"] = paths\n",
    "    df[\"Width\"] = widths\n",
    "    df.to_csv(f\"{type}CNN.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_root = \"merged_images\"\n",
    "\n",
    "output_train = os.path.join(output_root, \"train\")\n",
    "output_test = os.path.join(output_root, \"test\")\n",
    "\n",
    "os.makedirs(output_train, exist_ok=True)\n",
    "os.makedirs(output_test, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6849e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"trainCNN.csv\"):\n",
    "    new_train_df = generate_regression_dataset(train_df, output_train, train_data_path, type = \"train\", do_segment=False)\n",
    "    new_train_df[\"RootVolume\"] = new_train_df.groupby(\"FolderName\")[\"RootVolume\"].transform(\"mean\")\n",
    "else:\n",
    "    new_train_df = pd.read_csv(\"trainCNN.csv\")\n",
    "    \n",
    "if not os.path.exists(\"testCNN.csv\"):\n",
    "    new_test_df = generate_regression_dataset(test_df, output_test, test_data_path, type = \"test\")\n",
    "else:\n",
    "    new_test_df = pd.read_csv(\"testCNN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e559ecb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN      Unnamed: 0                ID  FolderName  PlantNumber Side  Start  End  \\\n",
      "56           56  ID_470797_Ayxwed  Dz9lpsl9ae            3    L     37   46   \n",
      "8             8  ID_216014_Djn5n6  Vinlgebupo            2    L     23   29   \n",
      "173         173  ID_769193_Hzpyfs  Vwsx0beaxb            4    L     27   39   \n",
      "385         385  ID_747792_Ofa0wh  Izbgyxre0g            6    R     22   33   \n",
      "366         366  ID_361716_Sufszh  Bb02c5k7wm            2    L     22   31   \n",
      "..          ...               ...         ...          ...  ...    ...  ...   \n",
      "323         323  ID_969350_G9jqgp  Izbgyxre0g            4    L     24   37   \n",
      "192         192  ID_258788_Bsotub  Xrrcqvdbkw            6    R     27   36   \n",
      "117         117  ID_309524_Tsywg8  Kjvcz6bjfj            4    R     26   39   \n",
      "47           47  ID_456912_Blrqzy  Ah4ubi4ggi            3    L     42   49   \n",
      "172         172  ID_858876_Vraxy7  Xdi1ipcemf            2    R     32   38   \n",
      "\n",
      "     RootVolume            Genotype  Stage  WasSegmented  \\\n",
      "56          2.5             TMEB419  Early         False   \n",
      "8           0.4           IBA980581  Early         False   \n",
      "173         2.9           IBA980581  Early         False   \n",
      "385         3.7           IBA154810  Early         False   \n",
      "366         1.8             TMEB693  Early         False   \n",
      "..          ...                 ...    ...           ...   \n",
      "323         1.3           IBA154810  Early         False   \n",
      "192         2.2           IBA154810  Early         False   \n",
      "117         2.1           IBA980581  Early         False   \n",
      "47          2.3  IITA-TMS-IBA000070  Early         False   \n",
      "172         4.3  IITA-TMS-IBA000070  Early         False   \n",
      "\n",
      "                                ImageSegments  Width  \n",
      "56   merged_images/train/ID_470797_Ayxwed.png    862  \n",
      "8    merged_images/train/ID_216014_Djn5n6.png    849  \n",
      "173  merged_images/train/ID_769193_Hzpyfs.png    904  \n",
      "385  merged_images/train/ID_747792_Ofa0wh.png    942  \n",
      "366  merged_images/train/ID_361716_Sufszh.png    928  \n",
      "..                                        ...    ...  \n",
      "323  merged_images/train/ID_969350_G9jqgp.png    947  \n",
      "192  merged_images/train/ID_258788_Bsotub.png    952  \n",
      "117  merged_images/train/ID_309524_Tsywg8.png    910  \n",
      "47   merged_images/train/ID_456912_Blrqzy.png    903  \n",
      "172  merged_images/train/ID_858876_Vraxy7.png    978  \n",
      "\n",
      "[308 rows x 13 columns]\n",
      "TEST      Unnamed: 0                ID  FolderName  PlantNumber Side  Start  End  \\\n",
      "260         260  ID_884849_Bmtyoy  Pfp24vx905            3    R     27   34   \n",
      "320         320  ID_747419_Zihzns  F1p0lhe1ij            4    R     30   37   \n",
      "144         144  ID_355808_Brk59j  Mrw7chmalv            6    L     18   23   \n",
      "52           52  ID_211500_Ndgm1d  Vbkivqphuz            5    L     20   32   \n",
      "210         210  ID_321332_Jptlgu  Pw4ytibfql            4    R     28   35   \n",
      "..          ...               ...         ...          ...  ...    ...  ...   \n",
      "302         302  ID_794803_Tvlbyb  Rxxe9bh6qn            7    L     31   40   \n",
      "327         327  ID_688192_Bdosyn  L8w7zu7wek            3    R     27   33   \n",
      "329         329  ID_271070_Fsmcir  Hc3b9gicdo            3    R     29   38   \n",
      "246         246  ID_219723_Urg3bc  Puya1uaaln            6    R     16   37   \n",
      "344         344  ID_467568_Bzuthn  Toaefqwoli            3    L     37   47   \n",
      "\n",
      "     RootVolume            Genotype  Stage  WasSegmented  \\\n",
      "260        1.70             TMEB419  Early         False   \n",
      "320        2.10  IITA-TMS-IBA000070  Early         False   \n",
      "144        3.30           IBA154810  Early         False   \n",
      "52         2.10             TMEB693  Early         False   \n",
      "210        1.50             TMEB419  Early         False   \n",
      "..          ...                 ...    ...           ...   \n",
      "302        0.01           IBA980581  Early         False   \n",
      "327        2.90  IITA-TMS-IBA000070  Early         False   \n",
      "329        3.10  IITA-TMS-IBA000070  Early         False   \n",
      "246        2.10             TMEB419  Early         False   \n",
      "344        0.50             TMEB419  Early         False   \n",
      "\n",
      "                                ImageSegments  Width  \n",
      "260  merged_images/train/ID_884849_Bmtyoy.png   1022  \n",
      "320  merged_images/train/ID_747419_Zihzns.png   1036  \n",
      "144  merged_images/train/ID_355808_Brk59j.png    915  \n",
      "52   merged_images/train/ID_211500_Ndgm1d.png    955  \n",
      "210  merged_images/train/ID_321332_Jptlgu.png    975  \n",
      "..                                        ...    ...  \n",
      "302  merged_images/train/ID_794803_Tvlbyb.png    963  \n",
      "327  merged_images/train/ID_688192_Bdosyn.png    963  \n",
      "329  merged_images/train/ID_271070_Fsmcir.png    983  \n",
      "246  merged_images/train/ID_219723_Urg3bc.png    917  \n",
      "344  merged_images/train/ID_467568_Bzuthn.png    875  \n",
      "\n",
      "[78 rows x 13 columns]\n",
      "new_test_df      Unnamed: 0                ID  FolderName  PlantNumber Side  Start  End  \\\n",
      "0             0  ID_208667_Hnkl8q  L5l1h3kekg            7    L     38   50   \n",
      "1             1  ID_285249_Jnjvav  Wgutyon8uu            6    R     23   37   \n",
      "2             2  ID_697947_Yec6bd  Mylwjeq6tq            3    R     19   42   \n",
      "3             3  ID_534638_X3j91f  Pfp24vx905            2    R     27   34   \n",
      "4             4  ID_929298_Xvymuz  Mrw7chmalv            4    R     30   43   \n",
      "..          ...               ...         ...          ...  ...    ...  ...   \n",
      "125         125  ID_652025_Ecubfg  L8w7zu7wek            4    L     33   51   \n",
      "126         126  ID_456856_Iucagp  Klhqlr0ako            2    L     38   47   \n",
      "127         127  ID_163551_Alfdb5  Vlqr6qhbqk            3    L     48   55   \n",
      "128         128  ID_947929_Qsuqln  Pfp24vx905            5    R     27   34   \n",
      "129         129  ID_225470_Hju47r  Qhqftdiz4q            6    L     28   38   \n",
      "\n",
      "               Genotype  Stage  WasSegmented  \\\n",
      "0    IITA-TMS-IBA000070  Early         False   \n",
      "1               TMEB419  Early         False   \n",
      "2             IBA980581  Early         False   \n",
      "3               TMEB419  Early         False   \n",
      "4             IBA154810  Early         False   \n",
      "..                  ...    ...           ...   \n",
      "125  IITA-TMS-IBA000070  Early         False   \n",
      "126             TMEB693  Early         False   \n",
      "127           IBA154810  Early         False   \n",
      "128             TMEB419  Early         False   \n",
      "129  IITA-TMS-IBA000070  Early         False   \n",
      "\n",
      "                               ImageSegments  Width  \n",
      "0    merged_images/test/ID_208667_Hnkl8q.png    978  \n",
      "1    merged_images/test/ID_285249_Jnjvav.png   1050  \n",
      "2    merged_images/test/ID_697947_Yec6bd.png   1006  \n",
      "3    merged_images/test/ID_534638_X3j91f.png   1022  \n",
      "4    merged_images/test/ID_929298_Xvymuz.png    910  \n",
      "..                                       ...    ...  \n",
      "125  merged_images/test/ID_652025_Ecubfg.png    964  \n",
      "126  merged_images/test/ID_456856_Iucagp.png    959  \n",
      "127  merged_images/test/ID_163551_Alfdb5.png    952  \n",
      "128  merged_images/test/ID_947929_Qsuqln.png   1022  \n",
      "129  merged_images/test/ID_225470_Hju47r.png    905  \n",
      "\n",
      "[130 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(new_train_df, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c507f538",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RootVolumeDataset(train, train_transform)\n",
    "test_dataset = RootVolumeDataset(test, test_transform)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "model = RootVolumeRegressor()\n",
    "\n",
    "if os.path.exists(\"cnn_models/model_no_seg.ckpt\"):\n",
    "    state_dict = torch.load(\"cnn_models/model_no_seg.ckpt\")['state_dict']\n",
    "    model.load_state_dict(state_dict)\n",
    "else:\n",
    "    trainer = L.Trainer(max_epochs = 20)\n",
    "    trainer.fit(model, train_dataloader)\n",
    "    os.makedirs(\"cnn_models\", exist_ok=True)\n",
    "    trainer.save_checkpoint(\"cnn_models/model_no_seg.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a2caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader <torch.utils.data.dataloader.DataLoader object at 0x7320042fa6f0>\n",
      "dummy_input tensor([[[[-0.3215, -1.7820, -0.3430,  ...,  1.9012, -0.0707,  0.6688],\n",
      "          [ 2.6402,  0.7574, -1.9474,  ..., -0.3053,  0.6065,  0.8220],\n",
      "          [ 0.6119,  0.4890,  1.2862,  ...,  0.5157,  0.2814,  0.8123],\n",
      "          ...,\n",
      "          [ 1.3485,  0.3681, -1.8600,  ...,  0.5698,  2.2335,  0.3354],\n",
      "          [-0.5802,  0.3578, -0.4872,  ...,  1.8528,  0.1232,  0.0520],\n",
      "          [ 1.2476, -0.5402,  0.2775,  ...,  1.1420,  0.3478,  0.4237]],\n",
      "\n",
      "         [[ 1.0047, -1.0976,  1.0387,  ..., -0.6027,  1.6541,  0.6535],\n",
      "          [-0.9187,  0.4677,  0.7053,  ...,  0.6562, -0.9255,  0.6144],\n",
      "          [-0.2071, -0.4263, -0.5910,  ...,  0.8113, -0.4720, -0.9351],\n",
      "          ...,\n",
      "          [ 0.3333,  1.3945,  0.3191,  ...,  0.3988, -0.1370,  0.5948],\n",
      "          [ 1.0884, -0.0552,  0.6049,  ..., -1.1653, -0.5788,  1.1405],\n",
      "          [-0.0938, -0.0118, -1.2353,  ..., -0.4395,  1.8589,  0.8068]],\n",
      "\n",
      "         [[ 1.2452,  1.8404,  0.5555,  ...,  0.7306,  0.4709, -0.5964],\n",
      "          [ 0.5006,  0.1005, -0.5525,  ..., -0.6151, -1.8627,  0.0737],\n",
      "          [-0.7556,  0.0338, -0.3467,  ...,  0.7192, -0.5398,  0.6390],\n",
      "          ...,\n",
      "          [ 0.1231,  0.9333,  0.2501,  ..., -0.1497, -1.2003,  0.6243],\n",
      "          [-0.6185,  1.4801, -1.2303,  ..., -0.0109,  0.0907, -0.6551],\n",
      "          [-0.8903, -0.4031,  0.1189,  ...,  0.3776, -0.6439, -0.9141]]]])\n"
     ]
    }
   ],
   "source": [
    "model = RootVolumeRegressor()\n",
    "\n",
    "# Load state dict\n",
    "if os.path.exists(\"cnn_models/model_no_seg.pt\"):\n",
    "    state_dict = torch.load(\"cnn_models/model_no_seg.pt\")['state_dict']\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    dummy_input = torch.randn(1, 3, 128, 128)\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        \"./cnn_models/model_no_seg.onnx\",\n",
    "        export_params=True,\n",
    "        opset_version=14,\n",
    "        do_constant_folding=True,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"output\"],\n",
    "        dynamic_axes={\n",
    "            \"input\": {0: \"batch_size\"},\n",
    "            \"output\": {0: \"batch_size\"}\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2332ec0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(\"cnn_models/model_no_seg.pt\")['state_dict']\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0cb912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input torch.Size([16, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([16]) torch.float32\n",
      "outputs torch.Size([16, 1]) torch.float32\n",
      "Input torch.Size([16, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([16]) torch.float32\n",
      "outputs torch.Size([16, 1]) torch.float32\n",
      "Input torch.Size([16, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([16]) torch.float32\n",
      "outputs torch.Size([16, 1]) torch.float32\n",
      "Input torch.Size([16, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([16]) torch.float32\n",
      "outputs torch.Size([16, 1]) torch.float32\n",
      "Input torch.Size([14, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([14]) torch.float32\n",
      "outputs torch.Size([14, 1]) torch.float32\n",
      "[     1.9505      1.8192       2.353       2.189      1.9886      2.1922      2.1927      1.7606       1.867      2.0731      2.2539      1.9707      1.9904      1.9205      2.1261      2.2658      1.9049      1.9366      1.7559      2.1192      1.6729       2.794      2.1179      2.2108      1.9178      1.9479\n",
      "      2.2986      2.1261      2.6299      2.4175      2.1015      1.6691      1.9731      1.9174      1.9687      1.9006      1.7606      2.0943      3.7035      1.7058      2.6267       2.232      2.0291      1.9982      1.8331      2.1576      2.1231      1.8108       1.939      1.9651      2.8584      2.0515\n",
      "      2.2623      1.9775      1.8272      1.6679      1.9848      1.9785      2.2108      2.4146      2.0291      1.9436      2.0035      2.0324      2.1179       2.232      2.1428      2.1428      1.9731      2.5902      2.7058      2.3108      2.0467       1.939      1.9687      1.8735      2.2249      1.8466]\n",
      "[        1.7         2.1         3.3         2.1         1.5         2.6         2.2         0.5         1.8         1.8         1.7         4.2         2.1         1.8         0.8         0.9           3         2.3         0.8         1.9         0.2         0.9         1.8         0.3         1.5         2.2\n",
      "         2.2         2.9         2.3         2.3         2.1         1.4         0.3         6.2         4.5         1.5         0.1         1.7         4.9         0.7         2.8         1.9         4.5         6.2         2.1         2.1         1.9         6.3         0.8         2.3         0.8         2.6\n",
      "         1.8         1.3         0.4         2.5         3.7         1.4         0.8         0.9         2.3         5.8         0.2         2.3         3.1         0.8         0.8         1.4         0.1         2.2         3.4         1.7         2.9        0.01         2.9         3.1         2.1         0.5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float32(1.4135247)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, target = get_model_preds(model, test_dataloader)\n",
    "calculate_rmse(preds, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f517f7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input torch.Size([16, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([16]) torch.float32\n",
      "outputs torch.Size([16, 1]) torch.float32\n",
      "Input torch.Size([16, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([16]) torch.float32\n",
      "outputs torch.Size([16, 1]) torch.float32\n",
      "Input torch.Size([16, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([16]) torch.float32\n",
      "outputs torch.Size([16, 1]) torch.float32\n",
      "Input torch.Size([16, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([16]) torch.float32\n",
      "outputs torch.Size([16, 1]) torch.float32\n",
      "Input torch.Size([14, 3, 128, 128]) torch.float32 tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         ...,\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0')\n",
      "Labels torch.Size([14]) torch.float32\n",
      "outputs torch.Size([14, 1]) torch.float32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>FolderName</th>\n",
       "      <th>PlantNumber</th>\n",
       "      <th>Side</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>RootVolume</th>\n",
       "      <th>Genotype</th>\n",
       "      <th>Stage</th>\n",
       "      <th>WasSegmented</th>\n",
       "      <th>ImageSegments</th>\n",
       "      <th>Width</th>\n",
       "      <th>Preds</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>260</td>\n",
       "      <td>ID_884849_Bmtyoy</td>\n",
       "      <td>Pfp24vx905</td>\n",
       "      <td>3</td>\n",
       "      <td>R</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>1.7</td>\n",
       "      <td>TMEB419</td>\n",
       "      <td>Early</td>\n",
       "      <td>False</td>\n",
       "      <td>merged_images/train/ID_884849_Bmtyoy.png</td>\n",
       "      <td>1022</td>\n",
       "      <td>1.959673</td>\n",
       "      <td>15.274888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>320</td>\n",
       "      <td>ID_747419_Zihzns</td>\n",
       "      <td>F1p0lhe1ij</td>\n",
       "      <td>4</td>\n",
       "      <td>R</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>2.1</td>\n",
       "      <td>IITA-TMS-IBA000070</td>\n",
       "      <td>Early</td>\n",
       "      <td>False</td>\n",
       "      <td>merged_images/train/ID_747419_Zihzns.png</td>\n",
       "      <td>1036</td>\n",
       "      <td>1.828650</td>\n",
       "      <td>12.921402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>144</td>\n",
       "      <td>ID_355808_Brk59j</td>\n",
       "      <td>Mrw7chmalv</td>\n",
       "      <td>6</td>\n",
       "      <td>L</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>3.3</td>\n",
       "      <td>IBA154810</td>\n",
       "      <td>Early</td>\n",
       "      <td>False</td>\n",
       "      <td>merged_images/train/ID_355808_Brk59j.png</td>\n",
       "      <td>915</td>\n",
       "      <td>2.352954</td>\n",
       "      <td>28.698372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>ID_211500_Ndgm1d</td>\n",
       "      <td>Vbkivqphuz</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>2.1</td>\n",
       "      <td>TMEB693</td>\n",
       "      <td>Early</td>\n",
       "      <td>False</td>\n",
       "      <td>merged_images/train/ID_211500_Ndgm1d.png</td>\n",
       "      <td>955</td>\n",
       "      <td>2.190696</td>\n",
       "      <td>4.318885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>210</td>\n",
       "      <td>ID_321332_Jptlgu</td>\n",
       "      <td>Pw4ytibfql</td>\n",
       "      <td>4</td>\n",
       "      <td>R</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>1.5</td>\n",
       "      <td>TMEB419</td>\n",
       "      <td>Early</td>\n",
       "      <td>False</td>\n",
       "      <td>merged_images/train/ID_321332_Jptlgu.png</td>\n",
       "      <td>975</td>\n",
       "      <td>1.978499</td>\n",
       "      <td>31.899929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                ID  FolderName  PlantNumber Side  Start  End  \\\n",
       "260         260  ID_884849_Bmtyoy  Pfp24vx905            3    R     27   34   \n",
       "320         320  ID_747419_Zihzns  F1p0lhe1ij            4    R     30   37   \n",
       "144         144  ID_355808_Brk59j  Mrw7chmalv            6    L     18   23   \n",
       "52           52  ID_211500_Ndgm1d  Vbkivqphuz            5    L     20   32   \n",
       "210         210  ID_321332_Jptlgu  Pw4ytibfql            4    R     28   35   \n",
       "\n",
       "     RootVolume            Genotype  Stage  WasSegmented  \\\n",
       "260         1.7             TMEB419  Early         False   \n",
       "320         2.1  IITA-TMS-IBA000070  Early         False   \n",
       "144         3.3           IBA154810  Early         False   \n",
       "52          2.1             TMEB693  Early         False   \n",
       "210         1.5             TMEB419  Early         False   \n",
       "\n",
       "                                ImageSegments  Width     Preds       MAPE  \n",
       "260  merged_images/train/ID_884849_Bmtyoy.png   1022  1.959673  15.274888  \n",
       "320  merged_images/train/ID_747419_Zihzns.png   1036  1.828650  12.921402  \n",
       "144  merged_images/train/ID_355808_Brk59j.png    915  2.352954  28.698372  \n",
       "52   merged_images/train/ID_211500_Ndgm1d.png    955  2.190696   4.318885  \n",
       "210  merged_images/train/ID_321332_Jptlgu.png    975  1.978499  31.899929  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "preds, target = get_model_preds(model, test_dataloader)\n",
    "targets=target\n",
    "preds = np.array(preds) if not isinstance(preds, np.ndarray) else preds\n",
    "targets = np.array(targets) if not isinstance(targets, np.ndarray) else targets\n",
    "res = []\n",
    "for i in range(len(targets)):\n",
    "    target = targets[i]\n",
    "    pred = preds[i]\n",
    "    if abs(target) < 1e-3:\n",
    "        res.append(0)\n",
    "    else:\n",
    "        res.append((np.abs(pred - target) / target) * 100)\n",
    "\n",
    "\n",
    "test[\"Preds\"] = preds\n",
    "test[\"MAPE\"] = res\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006e0cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.706\n"
     ]
    }
   ],
   "source": [
    "print(np.round(np.quantile(test[\"MAPE\"], q=0.5), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
